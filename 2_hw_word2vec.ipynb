{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "BXpR1XE6hO0O"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers datasets tabulate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "JwKtGkyogSmn"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from torch.utils.data import DataLoader\n",
        "from tabulate import tabulate\n",
        "from datasets import load_dataset\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from transformers import BertTokenizer\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCdfPYKRgSmo"
      },
      "source": [
        "This is a template of the notebook that you should complete and enrich with your own code.\n",
        "\n",
        "First cells will be the same than the ones of the lab on text convolution.\n",
        "\n",
        "# Data loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TdwlJJ1gSmp",
        "outputId": "741fda47-d76f-4080-bd78-2bb909cd1bc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['review', 'sentiment'],\n",
            "    num_rows: 50000\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "dataset = load_dataset(\"scikit-learn/imdb\", split=\"train\")\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0FUMHZ3g72D"
      },
      "source": [
        "# Pre-processing / Tokenization\n",
        "\n",
        "This is a very important step. It maybe boring but very important. In this session we will be lazy, but in real life, the time spent on inspecting and cleaning data is never wasted. It is true for text, but also for everything.\n",
        "\n",
        "\n",
        "\n",
        "In PyTorch, everything is tensor. Words are replaced by indices. A sentence, is therefore a sequence of indices (long integers). In the first HW, you constructed a `WhiteSpaceTokenizer`. Here we will use an already built tokenizer. It is more appropriate to transformers. It relies on sub-word units, and converts everything in lower case. This is not always the best choice, but here it will be sufficient. To quote the documentation, this tokenizer allows you to:\n",
        "- Tokenize (splitting strings in sub-word token strings), converttokens strings to ids and back, and encoding/decoding (i.e., tokenizing and converting to integers).\n",
        "- Add new tokens to the vocabulary in a way that is independent of the underlying structure (BPE, SentencePieceâ€¦).\n",
        "- Manage special tokens (like mask, beginning-of-sentence, etc.): adding them, assigning them to attributes in the tokenizer for easy access and making sure they are not split during tokenization.\n",
        "\n",
        "Here we are going to use the tokenizer from the well known Bert model, that we can directly download."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fhCY2FygSmr",
        "outputId": "0461da13-7225-49a2-badf-80f04efa316a"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "JkUifAjngSms"
      },
      "outputs": [],
      "source": [
        "def preprocessing_fn(x, tokenizer):\n",
        "    x[\"review_ids\"] = tokenizer(\n",
        "        x[\"review\"],\n",
        "        add_special_tokens=False,\n",
        "        truncation=True,\n",
        "        max_length=256,\n",
        "        padding=False,\n",
        "        return_attention_mask=False,\n",
        "    )[\"input_ids\"]\n",
        "    x[\"label\"] = 0 if x[\"sentiment\"] == \"negative\" else 1\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[100]"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer(\n",
        "        \"[UNK] \",\n",
        "        add_special_tokens=False,\n",
        "        truncation=True,\n",
        "        max_length=256,\n",
        "        padding=False,\n",
        "        return_attention_mask=False,\n",
        "    )[\"input_ids\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7uhbzZngSmt"
      },
      "source": [
        "Same celel than in the lab session.\n",
        "\n",
        "ðŸš§ **TODO** ðŸš§\n",
        "\n",
        "Read the documentation about HuggingFace dataset and complete the code below.\n",
        "You should:\n",
        "- Shuffle the dataset\n",
        "- For computational reasons, use only a total of **5000 samples**.\n",
        "- Tokenize the dataset with the `preprocessing_fn`. (*Hint: use the `Dataset.map` method from HuggingFace*).\n",
        "- Keep only columns `review_ids` and `label`.\n",
        "- Make a train/validation split, (**80% / 20%**). Call these dataset `train_set` and `valid_set`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lcp_ecU14bRP"
      },
      "source": [
        "## Q1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "61d0c45c257147749c9d0a7090215da1",
            "a55353b8096d4874a2c61a80340c3ba5",
            "003870b6e3824270a426c062fa886bb7",
            "fd27a2c4c87a499d8ab03d9c6bd9e5ca",
            "b35572a5c60e457bbf8f600c338c7281",
            "219a5818da6c4475828d1aafc83cbfad",
            "34a1df99e1874618a5365700b9825572",
            "d32760228abd417d88061cc0fcb84e11",
            "a42dc528fb2742c385803de38bcab1b8",
            "1e39e03b350947058a8e15e72c30df55",
            "ac6298a6a68a40989ed43b8c7afd4b9f"
          ]
        },
        "id": "MGNbn0IxgSmu",
        "outputId": "de26f37c-44a1-4016-8ccb-b4c2474e08e3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1bb034cf976c4dd58d438a47fa52bece",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "n_samples = 10000  # the number of training example\n",
        "\n",
        "# We first shuffle the data !\n",
        "data_shuffled = dataset.shuffle()\n",
        "\n",
        "# Select 5000 samples\n",
        "data_shuffled_sampled = data_shuffled.select(range(n_samples))\n",
        "\n",
        "# Tokenize the dataset\n",
        "data_tokenized = data_shuffled_sampled.map(lambda x: preprocessing_fn(x, tokenizer))\n",
        "\n",
        "# Remove useless columns\n",
        "data_tokenized = data_tokenized.remove_columns([\"review\", \"sentiment\"])\n",
        "\n",
        "# Split the train and validation\n",
        "split = data_tokenized.train_test_split(test_size=0.2)\n",
        "train_set = split['train']\n",
        "valid_set = split[\"test\"]\n",
        "\n",
        "document_train_set = train_set[\"review_ids\"]\n",
        "document_valid_set = valid_set[\"review_ids\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_l9gdqNN4iyp"
      },
      "source": [
        "# Q2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "ylKpnv_MvBnm"
      },
      "outputs": [],
      "source": [
        "def extract_words_contexts(document, radius, pad_token_id=0):\n",
        "    words = []\n",
        "    contexts = []\n",
        "    \n",
        "    for i in range(len(document)):\n",
        "        words.append(document[i])\n",
        "        \n",
        "        # Create context\n",
        "        context = []\n",
        "        for j in range(i - radius, i + radius + 1):\n",
        "            if j != i:  # Exclude the word itself\n",
        "                if 0 <= j < len(document):\n",
        "                    context.append(document[j])\n",
        "                else:\n",
        "                    # Handling borders: pad with pad_token_id (usually 0 for BERT)\n",
        "                    context.append(pad_token_id)\n",
        "        \n",
        "        contexts.append(context)\n",
        "    \n",
        "    return words, contexts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mhyjUID4tAg"
      },
      "source": [
        "# Q3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "Im7E1Xe4yzBQ"
      },
      "outputs": [],
      "source": [
        "def flatten_dataset_to_list(dataset, R):\n",
        "    all_ids = []\n",
        "    all_contexts = []\n",
        "\n",
        "    for document in tqdm(dataset):\n",
        "        ids, contexts = extract_words_contexts(document, R)\n",
        "        all_ids.extend(ids)\n",
        "        all_contexts.extend(contexts)\n",
        "\n",
        "    return all_ids, all_contexts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "u2pW_Gqp2tfv"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aed787a5a3164cae8f1125c64fb84bff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data_tokenized_flattened = flatten_dataset_to_list(data_tokenized[\"review_ids\"], 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGkHPrVM44C5"
      },
      "source": [
        "# Q4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "R,K = 10,5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "IKO9rmDYzyO_"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15c3ef4579e6442a8c228ca713886167",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/8000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "744dcb2821584f5aa439aa61fd0174f9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_ids, train_context = flatten_dataset_to_list(document_train_set, R)\n",
        "valid_ids, valid_context = flatten_dataset_to_list(document_valid_set, R)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bpgCoWP48WW"
      },
      "source": [
        "# Q5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "qCarhSvW0qbm"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ContextDataset(Dataset):\n",
        "    def __init__(self, words, contexts):\n",
        "      self.words = words\n",
        "      self.contexts = contexts\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.words)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        return self.words[idx], self.contexts[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "Oq1ET5oB2ry1"
      },
      "outputs": [],
      "source": [
        "train_set = ContextDataset(train_ids, train_context)\n",
        "valid_set = ContextDataset(valid_ids, valid_context)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obUP4qHwHoJD"
      },
      "source": [
        "# Q6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "j28tV4sxN8pA"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch, vocab_size, K):\n",
        "    word_ids = []\n",
        "    positive_context_ids = []\n",
        "    negative_context_ids = []\n",
        "\n",
        "    for word_id, pos_context in batch:\n",
        "        word_ids.append(word_id)\n",
        "        positive_context_ids.append(pos_context)\n",
        "        \n",
        "        # Generate negative context by random sampling\n",
        "        neg_context_size = 2 * len(pos_context) * K\n",
        "        neg_context = np.random.randint(0, vocab_size, size=neg_context_size).tolist()\n",
        "        negative_context_ids.append(neg_context)\n",
        "\n",
        "    return {\n",
        "        'word_id': torch.tensor(word_ids, dtype=torch.long),\n",
        "        'positive_context_ids': torch.tensor(positive_context_ids, dtype=torch.long),\n",
        "        'negative_context_ids': torch.tensor(negative_context_ids, dtype=torch.long)\n",
        "    }\n",
        "\n",
        "vocab_size = tokenizer.vocab_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFX4Buv1Hz4M"
      },
      "source": [
        "# Q7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "gOSxHemhJ-99"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, collate_fn=lambda x: collate_fn(x, vocab_size=vocab_size, K=K))\n",
        "valid_loader = DataLoader(valid_set, batch_size=32, shuffle=False, collate_fn=lambda x: collate_fn(x, vocab_size=vocab_size, K=K))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-Iu33Ur503h"
      },
      "source": [
        "# Q8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9C31Spk1H8HT",
        "outputId": "bcd7974f-27bf-43ec-b9d2-d671cb1c725c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'word_id': tensor([ 5993,  3086,  1028,  2001, 15040,  4771,  2055,  1012,  2022,  1996,\n",
              "          1013,  1010,  2200,  3143,  1996,  1056,  2242,  2023,  2023,  7987,\n",
              "          7864,  4765,  1010,  2919,  2039,  2437,  2039,  2000,  5201,  1012,\n",
              "          4178,  2053]),\n",
              " 'positive_context_ids': tensor([[ 1012,  1026,  7987,  1013,  1028,  1026,  7987,  1013,  1028,  1045,\n",
              "           2007,  2060,  7928,  2008,  1996,  2614,  2003,  2200,  2919,  1012],\n",
              "         [ 2023,  3185,  1012,  1045,  2442,  6449,  2008,  2009,  4046,  2026,\n",
              "           2471,  3202,  1012,  1045,  2293,  3080,  3152,  1998,  2023,  2003],\n",
              "         [ 7733,  4491,  1012,  1026,  7987,  1013,  1028,  1026,  7987,  1013,\n",
              "           1996,  5436,  2003,  3722,  2438,  1012, 19345, 13685,  5016, 12851],\n",
              "         [ 4407,  8811,  1999,  1996,  2220,  3150,  1036,  1055,  1010,  1045,\n",
              "           3149, 19967,  2044,  3071,  2842,  2253,  2000,  2793,  1012,  2009],\n",
              "         [ 2017,  2052,  5987,  2151,  3003,  2052,  2022,  2043,  7149,  2007,\n",
              "           1010,  2065,  2010,  2406,  2038,  2025,  2042, 11438,  1999,  2542],\n",
              "         [ 1998,  1045,  1005,  1049, 11498,  8458,  8180,  2075,  1010,  2057,\n",
              "           2256,  3382,  1011,  1011,  2057,  1005,  2222,  2074,  2031,  2000],\n",
              "         [    0,     0,  1045,  1005,  2310,  3191,  2070,  1997,  1996,  7928,\n",
              "           2023,  2143,  1998,  2064,  2069,  7505, 28732,  2008,  2070,  2111],\n",
              "         [ 1056,  2031,  2172,  5613,  2004,  1045,  2245,  2045,  2052,  2022,\n",
              "           2021,  1045,  2031,  2000,  2360,  1996,  2009,  2001,  1037,  2204],\n",
              "         [ 1996,  2143,  1010,  2174,  1010,  2008,  2023,  2180,  1005,  1056,\n",
              "           1996,  2553,  1010,  2061,  2525,  2057,  2024,  5191,  1012,  2054],\n",
              "         [ 1012,  2009,  1005,  1055,  6429,  2129, 10140,  3057,  2064,  2689,\n",
              "           2126,  1996,  2088,  3504,  1012,     0,     0,     0,     0,     0],\n",
              "         [ 2128,  2102,  2033,  2041,  1997,  2182,  1012,  1005,  1026,  7987,\n",
              "           1028,  1026,  7987,  1013,  1028,  1998,  1997,  2607,  1996, 12991],\n",
              "         [ 2210,  4268,  1006,  1996,  9416,  4378,  2005,  2023,  3185,  1007,\n",
              "           2021,  1045,  2245,  2054,  3047,  2000,  1996, 17109,  2934,  2012],\n",
              "         [ 7782,  1998, 15236,  2143,  1012,  1045,  5632,  2009,  1998,  2001,\n",
              "           7622,  2011,  1996,  7467,  1998,  2466,  1997,  2009,  1012,  1996],\n",
              "         [ 1037,  3151,  7977,  1011,  2041,  4038,  1010,  2009,  1005,  1055,\n",
              "           1998, 14395, 13044,  1025,  2043,  2017,  3422,  2009,  2007,  1996],\n",
              "         [ 2996, 11323,  2023,   999,  2672,  4777,  5292, 20330,  2370,  8729,\n",
              "           4353,  1997,  1005, 21049,  1005,  1010,  2044,  3773,  2009,  2370],\n",
              "         [ 2269,  1010,  2209,  2011,  2508, 18509,  1010,  2040,  2987,  1005,\n",
              "           5323,  2438,  1997,  1037,  3276,  2007,  2010,  2365,  1012,  5035],\n",
              "         [ 1005, 14369,  2013,  1996,  5940,  1011,  6400,  4693,  1000,  2030,\n",
              "           1012,  1012,  1012,  2092,  2009,  3475,  1005,  1056,  1037,  2307],\n",
              "         [ 2464,  1012,  2445,  1996,  5848,  1998,  2769,  2985,  2000,  2191,\n",
              "           2143,  1010,  2009,  2003, 16880,  2129,  7540,  1011, 26822,  2094],\n",
              "         [ 2069,  3728,  9845,  2408,  1996,  2088,  1997,  2981,  2143,  1012,\n",
              "           3047,  3243,  2011,  4926,  1010,  2007,  1996,  5456,  1997,  1037],\n",
              "         [14829,  2125,  2349,  2000,  2049, 15650,  1998,  9531,  1012,  1026,\n",
              "           1013,  1028,  1026,  7987,  1013,  1028,  1045,  5632,  2023,  2143],\n",
              "         [ 1005,  1056,  2393,  2021,  2228,  2008,  3071,  2842,  2040,  2038,\n",
              "           1037,  3319,  2061,  2521,  2001,  2070,  2126,  2920,  1999,  1996],\n",
              "         [ 1037,  2210,  2978,  1000,  2453,  2022,  2019,  2104,  9153, 18532,\n",
              "           1012,  1026,  7987,  1013,  1028,  1026,  7987,  1013,  1028,  2292],\n",
              "         [ 2007,  1037,  3460, 13071,  2105,  2007,  1037, 16216, 17071,  4675,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
              "         [ 1045,  2179,  2870,  5870, 25614,  2135,  1012,  2009,  2001,  2061,\n",
              "           2012,  2335,  2008,  2009,  2001, 29257,  1010,  2029,  2081,  2009],\n",
              "         [ 4933,   999,  2184,  1061,  2869,  2101,  1996,  4178,  2035,  2907,\n",
              "           2428,  2092,   999,  2017,  2123,  1005,  1056,     0,     0,     0],\n",
              "         [14423,  6579,  2192,  3544,  1998, 20735,  1996,  8962,  1011,  1011,\n",
              "           2009,  2046,  1037,  6743,  1997,  1037,  2192,  2612,  1012,  2092],\n",
              "         [18048,  1006, 12234, 27969,  6806,  3207,  7606, 10654,  6562,  2009,\n",
              "           2000,  2019, 25506,  3014,  1007,  1010,  2048,  8053,  9576, 22889],\n",
              "         [ 1996,  5889,  1999,  2023,  3185,  1010,  1998,  1996,  2769,  2109,\n",
              "           3965,  2023,  3185,  2052,  2031,  2042,  2488,  2109,  2000,  2707],\n",
              "         [ 1996,  2466,  1012,  2004,  1037,  5860, 19771,  5017,  1010,  1045,\n",
              "           2000,  2023,  3947,  2044,  1996,  2755,  4346,  2189,  2005,  1996],\n",
              "         [ 7987,  1013,  1028,  1045,  1005,  1049,  2025,  2437,  2023,  2039,\n",
              "           2027,  2018,  2195,  4436,  1010,  2004,  4076,  1024,  1026,  7987],\n",
              "         [ 2144,  2009,  1005,  1055, 26316,  1998,  2028,  1997,  2037,  2190,\n",
              "           2412,  1012,  1026,  7987,  1013,  1028,  1026,  7987,  1013,  1028],\n",
              "         [ 1010,  2053, 21146, 20722,  1011, 10973,  7245, 18458,  1010,  1998,\n",
              "           2030,  3683,  1007,  1012,  4312,  1010,  2292,  1005,  1055,  2681]]),\n",
              " 'negative_context_ids': tensor([[11832,   546, 14319,  ..., 14018, 16250, 28131],\n",
              "         [10511, 20845, 29494,  ...,  7703, 10900, 29566],\n",
              "         [18341,  8989,  6076,  ..., 14316, 27840, 11542],\n",
              "         ...,\n",
              "         [30128, 16790, 24509,  ..., 23658, 10347, 28835],\n",
              "         [21249, 28777,  1544,  ..., 10977, 18052,  2969],\n",
              "         [17789, 19930, 16911,  ...,   747,   360, 29164]])}"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch = next(iter(train_loader))\n",
        "batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32])"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch['word_id'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 20])"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch['positive_context_ids'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 200])"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch['negative_context_ids'].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1euf5ZN6Ai-"
      },
      "source": [
        "# Q9\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "0CnWBfWH6EnP"
      },
      "outputs": [],
      "source": [
        "class Word2Vec(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim,device = 'cuda'):\n",
        "        super(Word2Vec, self).__init__()\n",
        "        self.device = device\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim).to(device)\n",
        "        self.context_embeddings = nn.Embedding(vocab_size, embedding_dim).to(device)\n",
        "\n",
        "    def forward(self, word_id, pos_context_ids, neg_context_ids):\n",
        "        word_embed = self.word_embeddings(word_id)\n",
        "        #print(\"word\",word_embed.shape)\n",
        "\n",
        "        pos_context_embed = self.context_embeddings(pos_context_ids).to(self.device)\n",
        "        #print(\"pos\",pos_context_embed.shape)\n",
        "        neg_context_embed = self.context_embeddings(neg_context_ids).to(self.device)\n",
        "        #print(\"neg\",neg_context_embed.shape)\n",
        "\n",
        "        pos_dot_product = torch.bmm(pos_context_embed, word_embed.unsqueeze(2)).squeeze(2)\n",
        "        #print(\"pos_dot_product\",pos_dot_product.shape)\n",
        "\n",
        "        neg_dot_product = torch.bmm(neg_context_embed, word_embed.unsqueeze(2)).squeeze(2)\n",
        "        #print(\"neg_dot_product\",neg_dot_product.shape)\n",
        "\n",
        "        pos_similarity = torch.sigmoid(pos_dot_product)\n",
        "        #print(\"pos_similarity\",pos_similarity.shape)  # (batch_size, 2R)\n",
        "\n",
        "        neg_similarity = torch.sigmoid(neg_dot_product)\n",
        "        #print(\"neg_similarity\",neg_similarity.shape) # (batch_size, 2R * K)\n",
        "\n",
        "        pos_loss = -torch.log(pos_similarity + 1e-8).sum(1)  # Sum over all positive contexts\n",
        "        neg_loss = -torch.log(1 - neg_similarity + 1e-8).sum(1)  # Sum over all negative contexts\n",
        "        loss = pos_loss + neg_loss\n",
        "        #print(loss.shape)\n",
        "\n",
        "        return loss.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5fWaXJ1SSYH"
      },
      "source": [
        "# Q10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "51450"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "fjXBIuNKSPme"
      },
      "outputs": [],
      "source": [
        "def train_model(model, batch_size, epochs, lr =0.001):\n",
        "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, \n",
        "        collate_fn=lambda x: collate_fn(x, vocab_size=vocab_size, K=K))\n",
        "    \n",
        "    valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False,\n",
        "        collate_fn=lambda x: collate_fn(x, vocab_size=vocab_size, K=K))\n",
        "    \n",
        "    print(len(train_loader))\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    device = 'cuda'\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        total_loss_val = 0\n",
        "\n",
        "        print(\"### Train\")\n",
        "\n",
        "        for batch in tqdm(train_loader):\n",
        "\n",
        "            word_id = batch['word_id'].to(device)\n",
        "            positive_context_ids = batch['positive_context_ids'].to(device)\n",
        "            negative_context_ids = batch['negative_context_ids'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss = model(word_id, positive_context_ids, negative_context_ids)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(\"### Val\")\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(valid_loader):\n",
        "                word_id = batch['word_id'].to(device)\n",
        "                positive_context_ids = batch['positive_context_ids'].to(device)\n",
        "                negative_context_ids = batch['negative_context_ids'].to(device)\n",
        "                loss = model(word_id, positive_context_ids, negative_context_ids)\n",
        "                total_loss_val += loss.item()\n",
        "        \n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        avg_loss_val = total_loss_val / len(valid_loader)\n",
        "\n",
        "        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {avg_loss:.4f}, Val_Loss: {avg_loss_val:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQirp6JVTN_j",
        "outputId": "61252970-562a-460f-c0cc-0cf528e24c91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1608\n",
            "### Train\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eaf2b42c5e6447b49f0149704fb4adbc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1608 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Val\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4aa30c745da649ff81e6735a0860c530",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/402 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/10], Loss: 396.4575, Val_Loss: 142.2999\n",
            "### Train\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7e8cd9e82fe54cf39af7bc9a44ec57c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1608 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Val\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "23e1ff2500bf4bd6957a69b016d4f311",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/402 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [2/10], Loss: 95.3432, Val_Loss: 68.0042\n",
            "### Train\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3f57f77b381849639337b7016fe2491b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1608 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Val\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0156b00f38c04e8abfec3f2603423805",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/402 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [3/10], Loss: 53.7853, Val_Loss: 46.6459\n",
            "### Train\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "972158e37fd54cbcb9b3059b41c16c0e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1608 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Val\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "33e630a5f51842018332ea777a78cb88",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/402 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [4/10], Loss: 39.6485, Val_Loss: 37.7829\n",
            "### Train\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "41229f45187e4e8f93c9c5ce7a5ec3f6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1608 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Val\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d899859ba8f34a9ea0b033fdd961df14",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/402 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [5/10], Loss: 33.1618, Val_Loss: 33.2540\n",
            "### Train\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35c3c29bfdb54ace9483d743f2346b47",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1608 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Val\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be9940b2811a47e080b0aeda2d69c920",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/402 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [6/10], Loss: 29.6606, Val_Loss: 30.6831\n",
            "### Train\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fa3885275e0040338e1604c7dacb4aff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1608 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Val\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2e0ead79bc1d48e5aab8fea1378692e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/402 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [7/10], Loss: 27.5623, Val_Loss: 29.1009\n",
            "### Train\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6892b32b4cf54d2fb71585eaac286939",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1608 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Val\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19fc796f00534e47904e55275d5f83f7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/402 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [8/10], Loss: 26.2383, Val_Loss: 28.1105\n",
            "### Train\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c7d562988164c3aa149700eb9867da6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1608 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Val\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5705017a117544f0ad8509a7f934b4d9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/402 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [9/10], Loss: 25.3442, Val_Loss: 27.4358\n",
            "### Train\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7d9bfdb98c8459990ee55101bec06b9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1608 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "### Val\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17cf6ed7d79c4d989b7f3970bf418225",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/402 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [10/10], Loss: 24.7192, Val_Loss: 27.0071\n"
          ]
        }
      ],
      "source": [
        "# Define hyperparameters\n",
        "vocab_size = vocab_size  # Size of the vocabulary\n",
        "embedding_dim = 100  # Dimension of the word embeddings\n",
        "batch_size = 1024  # Batch size (B)\n",
        "epochs = 10  # Number of epochs (E)\n",
        "\n",
        "# Create the Word2Vec model\n",
        "model = Word2Vec(vocab_size, embedding_dim)\n",
        "\n",
        "# Assuming `train_dataset` is already prepared\n",
        "# Train the model\n",
        "train_model(model,batch_size, epochs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adqTK1ekjyVP"
      },
      "source": [
        "# Q11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "JCh6pa7eT5Qk"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def validate_word2vec(model, test_loader, R, K, B): # updated here\n",
        "    \n",
        "    # test_loader = DataLoader(test_dataset, batch_size=B, shuffle=False, collate_fn=lambda batch: collate_fn(batch, R, K)) # removed this line\n",
        "\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    total_pos_sim = 0\n",
        "    total_neg_sim = 0\n",
        "    pos_count = 0\n",
        "    neg_count = 0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation for validation\n",
        "        for batch in test_loader:\n",
        "            word_id = batch['word_id'].to('cuda')\n",
        "            positive_context_ids = batch['positive_context_ids'].to('cuda')\n",
        "            negative_context_ids = batch['negative_context_ids'].to('cuda')\n",
        "\n",
        "            # Get embeddings for words, positive contexts, and negative contexts\n",
        "            word_embeddings = model.word_embeddings(word_id)\n",
        "            positive_embeddings = model.context_embeddings(positive_context_ids)\n",
        "            negative_embeddings = model.context_embeddings(negative_context_ids)\n",
        "\n",
        "            # Cosine similarity for positive contexts\n",
        "            pos_similarity = F.cosine_similarity(word_embeddings.unsqueeze(1), positive_embeddings, dim=-1)\n",
        "            total_pos_sim += pos_similarity.sum().item()\n",
        "            pos_count += pos_similarity.numel()\n",
        "\n",
        "            # Cosine similarity for negative contexts\n",
        "            neg_similarity = F.cosine_similarity(word_embeddings.unsqueeze(1), negative_embeddings, dim=-1)\n",
        "            total_neg_sim += neg_similarity.sum().item()\n",
        "            neg_count += neg_similarity.numel()\n",
        "\n",
        "    # Average cosine similarities\n",
        "    avg_pos_sim = total_pos_sim / pos_count\n",
        "    avg_neg_sim = total_neg_sim / neg_count\n",
        "\n",
        "    print(f\"Avg Positive Context Similarity: {avg_pos_sim:.4f}\")\n",
        "    print(f\"Avg Negative Context Similarity: {avg_neg_sim:.4f}\")\n",
        "\n",
        "    return avg_pos_sim, avg_neg_sim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqArdcanBo62",
        "outputId": "4d0125e9-9753-4e1d-962c-9605f2f50315"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Avg Positive Context Similarity: 0.3385\n",
            "Avg Negative Context Similarity: -0.3321\n"
          ]
        }
      ],
      "source": [
        "avg_pos_sim, avg_neg_sim = validate_word2vec(model, valid_loader, R, K, batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_r7LTItj_aV"
      },
      "source": [
        "# Q12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), f\"model2_dim-{embedding_dim}_radius-{R}_ratio-{K}_batch-{batch_size}_epoch-{epochs}_samples-{n_samples}.ckpt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "R44FQZg6kRaF"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Word2Vec(\n",
              "  (word_embeddings): Embedding(30522, 100)\n",
              "  (context_embeddings): Embedding(30522, 100)\n",
              ")"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "003870b6e3824270a426c062fa886bb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d32760228abd417d88061cc0fcb84e11",
            "max": 5000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a42dc528fb2742c385803de38bcab1b8",
            "value": 5000
          }
        },
        "1e39e03b350947058a8e15e72c30df55": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "219a5818da6c4475828d1aafc83cbfad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34a1df99e1874618a5365700b9825572": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61d0c45c257147749c9d0a7090215da1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a55353b8096d4874a2c61a80340c3ba5",
              "IPY_MODEL_003870b6e3824270a426c062fa886bb7",
              "IPY_MODEL_fd27a2c4c87a499d8ab03d9c6bd9e5ca"
            ],
            "layout": "IPY_MODEL_b35572a5c60e457bbf8f600c338c7281"
          }
        },
        "a42dc528fb2742c385803de38bcab1b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a55353b8096d4874a2c61a80340c3ba5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_219a5818da6c4475828d1aafc83cbfad",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_34a1df99e1874618a5365700b9825572",
            "value": "Map:â€‡100%"
          }
        },
        "ac6298a6a68a40989ed43b8c7afd4b9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b35572a5c60e457bbf8f600c338c7281": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d32760228abd417d88061cc0fcb84e11": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd27a2c4c87a499d8ab03d9c6bd9e5ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e39e03b350947058a8e15e72c30df55",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ac6298a6a68a40989ed43b8c7afd4b9f",
            "value": "â€‡5000/5000â€‡[00:39&lt;00:00,â€‡154.26â€‡examples/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
