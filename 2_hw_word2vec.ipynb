{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BXpR1XE6hO0O"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JwKtGkyogSmn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from torch.utils.data import DataLoader\n",
        "from tabulate import tabulate\n",
        "from datasets import load_dataset\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from transformers import BertTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCdfPYKRgSmo"
      },
      "source": [
        "This is a template of the notebook that you should complete and enrich with your own code.\n",
        "\n",
        "First cells will be the same than the ones of the lab on text convolution.\n",
        "\n",
        "# Data loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TdwlJJ1gSmp",
        "outputId": "741fda47-d76f-4080-bd78-2bb909cd1bc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['review', 'sentiment'],\n",
            "    num_rows: 50000\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "dataset = load_dataset(\"scikit-learn/imdb\", split=\"train\")\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0FUMHZ3g72D"
      },
      "source": [
        "# Pre-processing / Tokenization\n",
        "\n",
        "This is a very important step. It maybe boring but very important. In this session we will be lazy, but in real life, the time spent on inspecting and cleaning data is never wasted. It is true for text, but also for everything.\n",
        "\n",
        "\n",
        "\n",
        "In PyTorch, everything is tensor. Words are replaced by indices. A sentence, is therefore a sequence of indices (long integers). In the first HW, you constructed a `WhiteSpaceTokenizer`. Here we will use an already built tokenizer. It is more appropriate to transformers. It relies on sub-word units, and converts everything in lower case. This is not always the best choice, but here it will be sufficient. To quote the documentation, this tokenizer allows you to:\n",
        "- Tokenize (splitting strings in sub-word token strings), converttokens strings to ids and back, and encoding/decoding (i.e., tokenizing and converting to integers).\n",
        "- Add new tokens to the vocabulary in a way that is independent of the underlying structure (BPE, SentencePieceâ€¦).\n",
        "- Manage special tokens (like mask, beginning-of-sentence, etc.): adding them, assigning them to attributes in the tokenizer for easy access and making sure they are not split during tokenization.\n",
        "\n",
        "Here we are going to use the tokenizer from the well known Bert model, that we can directly download."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fhCY2FygSmr",
        "outputId": "0461da13-7225-49a2-badf-80f04efa316a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JkUifAjngSms"
      },
      "outputs": [],
      "source": [
        "def preprocessing_fn(x, tokenizer):\n",
        "    x[\"review_ids\"] = tokenizer(\n",
        "        x[\"review\"],\n",
        "        add_special_tokens=False,\n",
        "        truncation=True,\n",
        "        max_length=256,\n",
        "        padding=False,\n",
        "        return_attention_mask=False,\n",
        "    )[\"input_ids\"]\n",
        "    x[\"label\"] = 0 if x[\"sentiment\"] == \"negative\" else 1\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7uhbzZngSmt"
      },
      "source": [
        "Same celel than in the lab session.\n",
        "\n",
        "ðŸš§ **TODO** ðŸš§\n",
        "\n",
        "Read the documentation about HuggingFace dataset and complete the code below.\n",
        "You should:\n",
        "- Shuffle the dataset\n",
        "- For computational reasons, use only a total of **5000 samples**.\n",
        "- Tokenize the dataset with the `preprocessing_fn`. (*Hint: use the `Dataset.map` method from HuggingFace*).\n",
        "- Keep only columns `review_ids` and `label`.\n",
        "- Make a train/validation split, (**80% / 20%**). Call these dataset `train_set` and `valid_set`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lcp_ecU14bRP"
      },
      "source": [
        "## Q1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "61d0c45c257147749c9d0a7090215da1",
            "a55353b8096d4874a2c61a80340c3ba5",
            "003870b6e3824270a426c062fa886bb7",
            "fd27a2c4c87a499d8ab03d9c6bd9e5ca",
            "b35572a5c60e457bbf8f600c338c7281",
            "219a5818da6c4475828d1aafc83cbfad",
            "34a1df99e1874618a5365700b9825572",
            "d32760228abd417d88061cc0fcb84e11",
            "a42dc528fb2742c385803de38bcab1b8",
            "1e39e03b350947058a8e15e72c30df55",
            "ac6298a6a68a40989ed43b8c7afd4b9f"
          ]
        },
        "id": "MGNbn0IxgSmu",
        "outputId": "de26f37c-44a1-4016-8ccb-b4c2474e08e3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61d0c45c257147749c9d0a7090215da1"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "n_samples = 5000  # the number of training example\n",
        "\n",
        "# We first shuffle the data !\n",
        "data_shuffled = dataset.shuffle()\n",
        "\n",
        "# Select 5000 samples\n",
        "data_shuffled_sampled = data_shuffled.select(range(n_samples))\n",
        "\n",
        "# Tokenize the dataset\n",
        "data_tokenized = data_shuffled_sampled.map(lambda x: preprocessing_fn(x, tokenizer))\n",
        "\n",
        "# Remove useless columns\n",
        "data_tokenized = data_tokenized.remove_columns([\"review\", \"sentiment\"])\n",
        "\n",
        "# Split the train and validation\n",
        "train_set = data_tokenized.train_test_split(test_size=0.2)[\"train\"]\n",
        "valid_set = data_tokenized.train_test_split(test_size=0.2)[\"test\"]\n",
        "\n",
        "document_train_set = train_set[\"review_ids\"]\n",
        "document_valid_set = valid_set[\"review_ids\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_l9gdqNN4iyp"
      },
      "source": [
        "# Q2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ylKpnv_MvBnm"
      },
      "outputs": [],
      "source": [
        "#A revoir car les C n'ont pas toujours la mÃªme taille, pour l'instant je l'utilise pour avancer\n",
        "\n",
        "def extract_words_contexts(w, R):\n",
        "    ids = []\n",
        "    pos_con = []\n",
        "    n = len(w)\n",
        "\n",
        "    for i in range(n):\n",
        "        ids.append(w[i])\n",
        "        context = []\n",
        "        left_context = w[max(0, i - R):i]  # words before w[i]\n",
        "        right_context = w[i + 1:min(n, i + R + 1)]  # words after w[i]\n",
        "        context = left_context + right_context\n",
        "        if len(context) < 2 * R:\n",
        "          if isinstance(context, tuple):\n",
        "                context = list(context)\n",
        "          context += [0] * (2 * R - len(context))\n",
        "        pos_con.append(context[:2 * R])\n",
        "\n",
        "    return ids, pos_con\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mhyjUID4tAg"
      },
      "source": [
        "# Q3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Im7E1Xe4yzBQ"
      },
      "outputs": [],
      "source": [
        "def flatten_dataset_to_list(dataset, R):\n",
        "    all_ids = []\n",
        "    all_contexts = []\n",
        "\n",
        "    for document in dataset:\n",
        "        ids, contexts = extract_words_contexts(document, R)\n",
        "        all_ids.extend(ids)\n",
        "        all_contexts.extend(contexts)\n",
        "\n",
        "    return all_ids, all_contexts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "u2pW_Gqp2tfv"
      },
      "outputs": [],
      "source": [
        "data_tokenized_flattened = flatten_dataset_to_list(data_tokenized[\"review_ids\"], 10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data_tokenized_flattened)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R44AM5AxQmBs",
        "outputId": "7b73dcc4-06e5-4dab-cd15-2d30d8963b55"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HBhpxG2Ezsi1"
      },
      "outputs": [],
      "source": [
        "R, K = 10, 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGkHPrVM44C5"
      },
      "source": [
        "# Q4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "IKO9rmDYzyO_"
      },
      "outputs": [],
      "source": [
        "train_ids, train_context = flatten_dataset_to_list(document_train_set, R)\n",
        "valid_ids, valid_context = flatten_dataset_to_list(document_valid_set, R)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRm7Oi0Q0hNA",
        "outputId": "3ea344f5-e281-459b-fc7c-dd155289a7f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4000\n",
            "1000\n"
          ]
        }
      ],
      "source": [
        "print(len(document_train_set))\n",
        "print(len(document_valid_set))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bpgCoWP48WW"
      },
      "source": [
        "# Q5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "qCarhSvW0qbm"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class sentiment(Dataset):\n",
        "    def __init__(self, words, contexts):\n",
        "      self.words = words\n",
        "      self.contexts = contexts\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.words)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        return self.words[idx], self.contexts[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Oq1ET5oB2ry1"
      },
      "outputs": [],
      "source": [
        "train_set = sentiment(train_ids, train_context)\n",
        "valid_set = sentiment(valid_ids, valid_context)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obUP4qHwHoJD"
      },
      "source": [
        "# Q6"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def collate_fn(batch, vocab_size, R, K):\n",
        "    word_ids, pos_con_ids = zip(*batch)\n",
        "\n",
        "    # Convert word ids and positive context ids to tensors\n",
        "    word_ids = torch.tensor(word_ids)\n",
        "    pos_con_ids = torch.tensor(pos_con_ids)\n",
        "\n",
        "    # Generate negative context by sampling from the vocabulary\n",
        "    neg_con_ids = torch.tensor([random.sample(range(vocab_size), 2 * R * K) for _ in range(len(word_ids))])\n",
        "\n",
        "    return {\"word_id\": word_ids, \"positive_context_ids\": pos_con_ids, \"negative_context_ids\": neg_con_ids}\n"
      ],
      "metadata": {
        "id": "j28tV4sxN8pA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFX4Buv1Hz4M"
      },
      "source": [
        "# Q7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "2YDT3OnNH2Oz"
      },
      "outputs": [],
      "source": [
        "batch_size = 10\n",
        "dataloader = DataLoader(\n",
        "        dataset=data_tokenized_flattened, batch_size=batch_size, collate_fn= lambda x : collate_fn(x, R, K)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, collate_fn=lambda x: collate_fn(x, vocab_size=n_samples, R=R, K=5))\n",
        "\n",
        "valid_loader = DataLoader(valid_set, batch_size=32, shuffle=False, collate_fn=lambda x: collate_fn(x, vocab_size=n_samples, R=R, K=5))"
      ],
      "metadata": {
        "id": "gOSxHemhJ-99"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q8"
      ],
      "metadata": {
        "id": "q-Iu33Ur503h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9C31Spk1H8HT",
        "outputId": "bcd7974f-27bf-43ec-b9d2-d671cb1c725c",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R = 10, K = 2\n",
            "{'word_id': tensor([ 2017,  2245,  2819,  1998,  1056,  2023,  2428,  5537,  1999,  1010,\n",
            "         1998, 14726, 14976,   999,  2024,  3057,  1012,  1997,  1997,  2299,\n",
            "         1011,  1037,  1037,  1010,  2017,  1013,  2155,  1996,  2062,  2100,\n",
            "         5488,  1997]), 'positive_context_ids': tensor([[ 1012,  2045,  2024,  2035, 11901,  1997, 21635, 12817,  2000,  2562,\n",
            "         11770,  1010,  1998,  1996,  1006,  2512,  1011,  6052,  1007,  6050],\n",
            "        [ 2236,  1012,  2043,  1045,  2387,  2023,  2005,  5096,  1010,  1045,\n",
            "          2009,  2001,  1037, 10036, 10973,  2125,  1997, 16113,  1012,  2053],\n",
            "        [ 5064,  2028,  9020,  2000, 19815,  2039,  2006,  2585, 23680, 18083,\n",
            "          1998,  2507,  2032,  1037,  9152,  2361,  1012,  2049,  2004,  2065],\n",
            "        [ 8022,  1006,  2004,  6382, 21909,  1007,  1010,  1037, 10571,  9431,\n",
            "          4770, 15876, 22516,  2099,  1012,  2002,  8480,  2007,  3376,  2684],\n",
            "        [ 5691,  2006,  6833,  2066,  6480,  1010,  2087,  2111,  2123,  1005,\n",
            "          2215,  2000,  3422,  2068,  1012,  1998,  1996,  3924,  2008,  2079],\n",
            "        [ 1997,  1996,  2711,  2016,  7566,  2007,  1012,  2043,  1045,  2387,\n",
            "          2143,  1010,  1045,  9768, 21617, 27040,  2062,  2007,  2014,  2836],\n",
            "        [ 2926,  2012,  1037,  2621,  4518,  3004,  1011,  2017,  1005,  2222,\n",
            "          5959,  2023,  2143,  1012,  1026,  7987,  1013,  1028,  1026,  7987],\n",
            "        [ 2017,  2424,  4426,  3666,  2023,  2153,  1010,  2298,  2012,  1996,\n",
            "          2073, 11968,  2063,  1998,  2194,  2024,  3788,  2083,  1037,  1000],\n",
            "        [ 2793,  2362,  1006,  5525,  1037,  5913,  1997,  6498,  1005,  1055,\n",
            "          2613,  2166,  1010,  2004,  2107,  1037,  2518,  2052,  2196,  4148],\n",
            "        [ 1012,  1012,  1012,  1000,  2059,  2074,  2004,  1045,  2245,  2009,\n",
            "          1008,  8744,  1008,  2052,  4148,  1012,  2009,  1005,  1055,  1037],\n",
            "        [11345,  1999,  2029,  1037,  2775,  2052,  2031,  2404,  2069,  5699,\n",
            "         12136,  3241,  2008,  2138,  2122, 12760,  2024,  1996,  2190,  1010],\n",
            "        [ 2115,  3242,  2013,  1996,  2927,  2000,  1996,  2203,  1012,  2023,\n",
            "          1998, 11087,  1011,  6355, 27699,  7174,  2071,  2092,  2022,  2649],\n",
            "        [ 2128,  3048,  2000,  2178,  2160,  1010,  2027,  2202,  2006,  1037,\n",
            "          2027,  1005,  2128,  7708,  2668,  1012,  2203,  1997, 27594,  2121],\n",
            "        [ 2428,  2003,  2200,  2200,  2200,  2200,  2200,  2200,  2200,  2919,\n",
            "          2079,  4426,  1037,  7927,  1998, 21271,  2006,  1037,  2312,  8903],\n",
            "        [ 2265,  2035,  1996,  2062, 22249,  1012,  2569,  6368,  1010,  2040,\n",
            "          2814,  2004,  2092,  2081,  2005,  1037,  3835,  4474,  2205,  1012],\n",
            "        [ 3130,  1999,  1996, 10693,  5691,  1010,  5006,  9899,  1998,  8094,\n",
            "          1010,  1998,  3866,  2014,  1012,  1999,  4439,  8220,  1010,  2004],\n",
            "        [ 2066,  2000,  2113,  2065,  2023,  3185,  2003,  2800,  2006,  4966,\n",
            "          1026,  7987,  1013,  1028,  1026,  7987,  1013,  1028,  1996,  2717],\n",
            "        [ 2008,  2003,  2825,  2005,  5380,  1007,  1010,  2023,  2003,  2028,\n",
            "          2216,  3152,  1045,  2052,  3422,  2006,  1037, 16373,  2154,  1012],\n",
            "        [ 2054,  2031,  2057,  2464,  1996,  2034,  1010,  3308,  1010,  5537,\n",
            "          2824,  2005,  2059,  1029,  1026,  7987,  1013,  1028,  1026,  7987],\n",
            "        [11559,  2154,  1012,  1045,  2196,  2215,  2000,  2963,  1996,  4323,\n",
            "          2153,  1010,  2004,  2009,  1005,  1055,  2209,  4703,  2438,  2058],\n",
            "        [ 1996, 14354,  2030,  1000,  2391,  1000,  1997,  2023,  2143,  2003,\n",
            "          2004,  2045,  2003,  2200,  2210, 16747,  2592,  3024,  1999,  1996],\n",
            "        [ 2193,  1997,  5876,  2191,  2009,  3733,  2005,  2033,  2000,  2110,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [ 2089,  2031,  2049,  3471,  1010,  2043,  3666,  2069,  2028,  2792,\n",
            "          2733,  1010,  2021,  1996,  4966,  4289,  2003,  2941,  2019,  9788],\n",
            "        [ 2038,  1037,  2843,  1997,  4569,  2667,  1011,  1998,  2009,  3065,\n",
            "          3391,  2076,  2014,  2034,  3962,  1997,  5379,  4690, 13068,  2007],\n",
            "        [ 1996,  1000,  2396,  1000,  1029,   999,  1029,  2092,  1010,  2065,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [ 2000,  2022,  2511,  1012,  1026,  7987,  1013,  1028,  1026,  7987,\n",
            "          1028,  2023,  3181, 28063,  1010,  1996,  2034,  2000,  2022,  2218],\n",
            "        [ 2265,  2068,  4780, 23277, 25508,  2075, 22156,  2006,  2023,  3532,\n",
            "          1012,  2348,  1010,  2043,  2017,  2633,  2079,  2131,  2000,  2156],\n",
            "        [ 2491,  1997,  1996,  8582,  1010,  2021,  2036,  9756,  2112,  1997,\n",
            "          2250,  5536,  2012,  1996,  3199,  1012,  2028,  2154,  2023,  3124],\n",
            "        [ 4224,  1010,  1999,  2074,  2058,  2322,  2781,  1010,  2071,  5308,\n",
            "          7603,  1998,  3689,  2084,  2087,  2048,  2847,  5691,  2651,  1012],\n",
            "        [ 2123,  1005,  1056,  2131,  2033,  3308,  1024,  2023, 18178,  2229,\n",
            "          1998,  2128,  7559,  5732,  8016,  2005,  1037,  5469,  2143,  2003],\n",
            "        [28051,  1010,  2000,  3710,  2111,  2725,  2273,  4818,  1010,  4895,\n",
            "         11001,  5841,  1010,  4428,  1010,  2810,  4385,  1012,  1998,  2947],\n",
            "        [ 1037,  2414,  2273,  1005,  1055,  2252,  1998, 10229,  1996,  4767,\n",
            "          1996,  2190,  3274,  8519,  1999,  2237,  1010,  2002, 15539,  1996]]), 'negative_context_ids': tensor([[1748, 2245,  170,  ..., 4990,  447, 3106],\n",
            "        [2371, 4331, 4584,  ..., 4661, 1531, 1487],\n",
            "        [3382, 1213, 1256,  ..., 4686, 4229, 1642],\n",
            "        ...,\n",
            "        [2653, 1794, 4202,  ..., 3239, 2196, 4858],\n",
            "        [1705, 2147, 3359,  ..., 4955, 2930, 4180],\n",
            "        [2101, 1551, 1491,  ..., 2663, 1567, 3002]])}\n",
            "Word IDs: tensor([ 2017,  2245,  2819,  1998,  1056,  2023,  2428,  5537,  1999,  1010,\n",
            "         1998, 14726, 14976,   999,  2024,  3057,  1012,  1997,  1997,  2299,\n",
            "         1011,  1037,  1037,  1010,  2017,  1013,  2155,  1996,  2062,  2100,\n",
            "         5488,  1997])\n",
            "Positive Context: tensor([[ 1012,  2045,  2024,  2035, 11901,  1997, 21635, 12817,  2000,  2562,\n",
            "         11770,  1010,  1998,  1996,  1006,  2512,  1011,  6052,  1007,  6050],\n",
            "        [ 2236,  1012,  2043,  1045,  2387,  2023,  2005,  5096,  1010,  1045,\n",
            "          2009,  2001,  1037, 10036, 10973,  2125,  1997, 16113,  1012,  2053],\n",
            "        [ 5064,  2028,  9020,  2000, 19815,  2039,  2006,  2585, 23680, 18083,\n",
            "          1998,  2507,  2032,  1037,  9152,  2361,  1012,  2049,  2004,  2065],\n",
            "        [ 8022,  1006,  2004,  6382, 21909,  1007,  1010,  1037, 10571,  9431,\n",
            "          4770, 15876, 22516,  2099,  1012,  2002,  8480,  2007,  3376,  2684],\n",
            "        [ 5691,  2006,  6833,  2066,  6480,  1010,  2087,  2111,  2123,  1005,\n",
            "          2215,  2000,  3422,  2068,  1012,  1998,  1996,  3924,  2008,  2079],\n",
            "        [ 1997,  1996,  2711,  2016,  7566,  2007,  1012,  2043,  1045,  2387,\n",
            "          2143,  1010,  1045,  9768, 21617, 27040,  2062,  2007,  2014,  2836],\n",
            "        [ 2926,  2012,  1037,  2621,  4518,  3004,  1011,  2017,  1005,  2222,\n",
            "          5959,  2023,  2143,  1012,  1026,  7987,  1013,  1028,  1026,  7987],\n",
            "        [ 2017,  2424,  4426,  3666,  2023,  2153,  1010,  2298,  2012,  1996,\n",
            "          2073, 11968,  2063,  1998,  2194,  2024,  3788,  2083,  1037,  1000],\n",
            "        [ 2793,  2362,  1006,  5525,  1037,  5913,  1997,  6498,  1005,  1055,\n",
            "          2613,  2166,  1010,  2004,  2107,  1037,  2518,  2052,  2196,  4148],\n",
            "        [ 1012,  1012,  1012,  1000,  2059,  2074,  2004,  1045,  2245,  2009,\n",
            "          1008,  8744,  1008,  2052,  4148,  1012,  2009,  1005,  1055,  1037],\n",
            "        [11345,  1999,  2029,  1037,  2775,  2052,  2031,  2404,  2069,  5699,\n",
            "         12136,  3241,  2008,  2138,  2122, 12760,  2024,  1996,  2190,  1010],\n",
            "        [ 2115,  3242,  2013,  1996,  2927,  2000,  1996,  2203,  1012,  2023,\n",
            "          1998, 11087,  1011,  6355, 27699,  7174,  2071,  2092,  2022,  2649],\n",
            "        [ 2128,  3048,  2000,  2178,  2160,  1010,  2027,  2202,  2006,  1037,\n",
            "          2027,  1005,  2128,  7708,  2668,  1012,  2203,  1997, 27594,  2121],\n",
            "        [ 2428,  2003,  2200,  2200,  2200,  2200,  2200,  2200,  2200,  2919,\n",
            "          2079,  4426,  1037,  7927,  1998, 21271,  2006,  1037,  2312,  8903],\n",
            "        [ 2265,  2035,  1996,  2062, 22249,  1012,  2569,  6368,  1010,  2040,\n",
            "          2814,  2004,  2092,  2081,  2005,  1037,  3835,  4474,  2205,  1012],\n",
            "        [ 3130,  1999,  1996, 10693,  5691,  1010,  5006,  9899,  1998,  8094,\n",
            "          1010,  1998,  3866,  2014,  1012,  1999,  4439,  8220,  1010,  2004],\n",
            "        [ 2066,  2000,  2113,  2065,  2023,  3185,  2003,  2800,  2006,  4966,\n",
            "          1026,  7987,  1013,  1028,  1026,  7987,  1013,  1028,  1996,  2717],\n",
            "        [ 2008,  2003,  2825,  2005,  5380,  1007,  1010,  2023,  2003,  2028,\n",
            "          2216,  3152,  1045,  2052,  3422,  2006,  1037, 16373,  2154,  1012],\n",
            "        [ 2054,  2031,  2057,  2464,  1996,  2034,  1010,  3308,  1010,  5537,\n",
            "          2824,  2005,  2059,  1029,  1026,  7987,  1013,  1028,  1026,  7987],\n",
            "        [11559,  2154,  1012,  1045,  2196,  2215,  2000,  2963,  1996,  4323,\n",
            "          2153,  1010,  2004,  2009,  1005,  1055,  2209,  4703,  2438,  2058],\n",
            "        [ 1996, 14354,  2030,  1000,  2391,  1000,  1997,  2023,  2143,  2003,\n",
            "          2004,  2045,  2003,  2200,  2210, 16747,  2592,  3024,  1999,  1996],\n",
            "        [ 2193,  1997,  5876,  2191,  2009,  3733,  2005,  2033,  2000,  2110,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [ 2089,  2031,  2049,  3471,  1010,  2043,  3666,  2069,  2028,  2792,\n",
            "          2733,  1010,  2021,  1996,  4966,  4289,  2003,  2941,  2019,  9788],\n",
            "        [ 2038,  1037,  2843,  1997,  4569,  2667,  1011,  1998,  2009,  3065,\n",
            "          3391,  2076,  2014,  2034,  3962,  1997,  5379,  4690, 13068,  2007],\n",
            "        [ 1996,  1000,  2396,  1000,  1029,   999,  1029,  2092,  1010,  2065,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [ 2000,  2022,  2511,  1012,  1026,  7987,  1013,  1028,  1026,  7987,\n",
            "          1028,  2023,  3181, 28063,  1010,  1996,  2034,  2000,  2022,  2218],\n",
            "        [ 2265,  2068,  4780, 23277, 25508,  2075, 22156,  2006,  2023,  3532,\n",
            "          1012,  2348,  1010,  2043,  2017,  2633,  2079,  2131,  2000,  2156],\n",
            "        [ 2491,  1997,  1996,  8582,  1010,  2021,  2036,  9756,  2112,  1997,\n",
            "          2250,  5536,  2012,  1996,  3199,  1012,  2028,  2154,  2023,  3124],\n",
            "        [ 4224,  1010,  1999,  2074,  2058,  2322,  2781,  1010,  2071,  5308,\n",
            "          7603,  1998,  3689,  2084,  2087,  2048,  2847,  5691,  2651,  1012],\n",
            "        [ 2123,  1005,  1056,  2131,  2033,  3308,  1024,  2023, 18178,  2229,\n",
            "          1998,  2128,  7559,  5732,  8016,  2005,  1037,  5469,  2143,  2003],\n",
            "        [28051,  1010,  2000,  3710,  2111,  2725,  2273,  4818,  1010,  4895,\n",
            "         11001,  5841,  1010,  4428,  1010,  2810,  4385,  1012,  1998,  2947],\n",
            "        [ 1037,  2414,  2273,  1005,  1055,  2252,  1998, 10229,  1996,  4767,\n",
            "          1996,  2190,  3274,  8519,  1999,  2237,  1010,  2002, 15539,  1996]])\n",
            "Negative Context: tensor([[1748, 2245,  170,  ..., 4990,  447, 3106],\n",
            "        [2371, 4331, 4584,  ..., 4661, 1531, 1487],\n",
            "        [3382, 1213, 1256,  ..., 4686, 4229, 1642],\n",
            "        ...,\n",
            "        [2653, 1794, 4202,  ..., 3239, 2196, 4858],\n",
            "        [1705, 2147, 3359,  ..., 4955, 2930, 4180],\n",
            "        [2101, 1551, 1491,  ..., 2663, 1567, 3002]])\n",
            "R = 10, K = 2\n",
            "{'word_id': tensor([ 2127,  2428, 10418,  1997,  9066,  1996, 24653,  2009,  1037,  3616,\n",
            "         1012,  1996,  1010,  2017,  1026, 13446,  2142,  2068,  2051,  2105,\n",
            "         3248,  2031,  2059,  1005,  1996,  7987,  4511,  2389, 16266,  1037,\n",
            "         1998,  3550]), 'positive_context_ids': tensor([[ 2054,  2016,  2758,  1010,  2030,  2130,  4209,  2054,  2016,  2758,\n",
            "          2016,  2758,  2009,  1012,  2016,  3662,  2053, 10218,  7603,  2012],\n",
            "        [ 2009,  2515,  2272,  2041,  1997,  2187,  2492,  1010,  1998,  3475,\n",
            "          1005,  1056,  2054,  2017,  1005,  2128,  8074,  1012,  2021,     0],\n",
            "        [ 3459,  1010, 21688,  3257,  1010,  1998,  1010,  3383,  1010,  1996,\n",
            "          2143,  3556,  2412,  2517,  1010,  2191,  1000,  5102,  2000,  3102],\n",
            "        [ 2100,  9378,  2100,  6456,  2158,  1012,  1037,  2613,  2919,  2544,\n",
            "          1037,  6456,  2158,  1012,  1998,  2002,  4152,  2920,  2007,  4531],\n",
            "        [ 4556,  2189, 20305,  2097,  2053,  4797,  6709,  1996,  2189,  1996,\n",
            "          2015,  2024,  2652,  1012, 19643,  2059, 13675, 27174,  1010,  1000],\n",
            "        [ 1996,  4184,  7905, 21363,  1011,  2002,  2003,  2667,  2000,  2202,\n",
            "          2252,  2058,  1998,  2735,  2009,  2046,  1037,  1000, 11662,  3698],\n",
            "        [ 2000,  2131,  2046,  1996,  2250,  2486,  2914,  1010,  9530,  3401,\n",
            "          1997,  1037,  5436,  1006,  2007,  2393,  2013,  2010,  2128,  7559],\n",
            "        [ 2025,  2019,  8052,  2028,  1012,  2085,  2008,  1045,  2031,  2464,\n",
            "          2153,  2007,  2070,  2814,  2006,  4966,  1006,  2027,  2018,  2025],\n",
            "        [ 6749,  2005,  2111,  2559,  2005,  1037,  3835,  2210,  6172,  2007,\n",
            "          2200,  3835,  3407,  4566,  1012,     0,     0,     0,     0,     0],\n",
            "        [ 2435,  2019,  5151,  2836,  2007,  7564,  1997,  3153,  1998,  3315,\n",
            "          1012,  6506,  9413, 13153,  1010,  1006, 16123,  7867,  1007,  2435],\n",
            "        [ 7539,  1010,  1045,  2293,  1996, 17841,  3512,  4022,  2009,  2038,\n",
            "          2673,  1998,  3071,  1999,  4698,  1005,  1055,  1006,  2209,  2011],\n",
            "        [ 2358, 24388,  9513,  1000, 18201,  2008,  4300,  4740,  2000, 20432,\n",
            "         15577,  5467,  2007,  1012,  1026,  7987,  1013,  1028,  1026,  7987],\n",
            "        [ 2838,  1012,  1012,  1012,  2138,  2045,  2020,  2053,  6450,  4520,\n",
            "         12703,  1010,  2030,  2152,  1011, 21125,  3185,  3340,  1012,  1026],\n",
            "        [ 2907,  1996,  4378,  1998,  3561,  2007, 13764,  8649,  2015,  2029,\n",
            "          2052,  2031,  2657,  1037,  2454,  2335,  2077,  1012,  2028,  1997],\n",
            "        [16006,  1000,  1999,  1996,  2694, 12661,  1026,  7987,  1013,  1028,\n",
            "          7987,  1013,  1028,  2122,  2024,  2070,  1997,  1996,  2307,  4895],\n",
            "        [ 2002,  1004,  2010, 14711,  5630,  2000,  2907,  1996,  2972,  3345,\n",
            "          2061,  2027,  2064,  2031,  2019,  8917,  2100,  2007, 24696,  1004],\n",
            "        [ 1997,  2023,  2143,  1011, 15587,  1012,  2320,  2067,  1999,  1996,\n",
            "          2163,  2016,  2003,  2025,  5204,  2008,  2016,  2071,  2022,  9359],\n",
            "        [ 1012,  2005,  3183, 11867, 20051,  3334,  2730,  2370,  1010,  4292,\n",
            "          2039,  2000,  2202,  1996,  7499,  2061,  2002,  2071,  2468,  1996],\n",
            "        [ 2216, 21877,  5874, 26650,  2015,  1012,  1012,  1012,  2021,  2023,\n",
            "          2105,  2009,  1005,  1055,  9442,  1998,  2062, 21699,  1012,  1996],\n",
            "        [ 1012, 25212,  2099,  1010,  1045,  2812, 25516,  2015,  2108,  7671,\n",
            "          2006,  5793, 14666,  1007,  1010,  6649,  9188,  1999,  7982,  1010],\n",
            "        [ 3881,  6287,  5974,  2402,  9079,  2204,  2075,  1010,  2040,  5829,\n",
            "          1999,  2007, 22344,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [ 7437, 10554,  2652,  1037,  7743,  1024,  1037,  2839,  2040,  2453,\n",
            "          2042,  8282,  2521, 10524,  2322,  2086,  2077,  1007,  1010,  2008],\n",
            "        [ 2037,  3317,  1010,  2383,  4689,  3348,  2007,  2068,  1010,  1998,\n",
            "          5983,  2068,  1006,  3272,  1996,  2034,  6778,  1010,  2040,  2027],\n",
            "        [ 5458,  1997,  1996,  1000,  4286, 11891,  1000, 18856, 17322,  2008,\n",
            "          1055,  2430,  2000,  2296,  3185,  1012,  1045,  2113,  2017,  2064],\n",
            "        [ 2000,  3422,  1037,  3185,  2008,  2003,  2667,  2000,  4167, 28556,\n",
            "         11678,  1012,  2092,  2023,  2003,  1996,  4060,  1997,  1996, 19070],\n",
            "        [ 2009,  7796,  2015,  2019,  2809,  2041,  1997,  2184,  1012,  1026,\n",
            "          1013,  1028,  1026,  7987,  1013,  1028,  1996,  3276,  2090,  2257],\n",
            "        [ 1999,  1996,  2168,  2126,  2019,  6450,  1010,  2152,  3737,  2413,\n",
            "          2515,  1012,  2009,  3727,  2017,  2007,  1037,  2200,  2986,  2044],\n",
            "        [ 2925, 12773,  2395, 12406,  5206, 15487,  1998,  5469,  2143,  2358,\n",
            "         18367, 10768, 17460,  2089,  2638,  1006,  2652,  1037,  2016,  5480],\n",
            "        [ 7110,  1005,  1056,  4276,  1037,  2298,  1024,  1996,  1005,  4086,\n",
            "         14691,  2532,  1005,  2193,  3794,  2327,  3238,  7165,  3057,  2003],\n",
            "        [ 1000,  4628,  1024,  1000,  2469,  1010,  1045,  2064,  3298,  2005,\n",
            "          2096,  1012,  1000,  1006,  2320,  2766,  2058,  1010,  1996,  4062],\n",
            "        [ 2004,  1037, 10170,  1010,  1037,  5268,  1005,  1055,  5268,  1010,\n",
            "          1037,  8235, 19717,  2937,  1999,  1996,  2492,  1997, 23387,  8309],\n",
            "        [ 2469,  1010,  1996,  2381,  1999,  2023,  3185,  2001,  1000,  5365,\n",
            "          1000,  1011,  1011,  2021,  2009,  1005,  1055,  2521,  2013,  2108]]), 'negative_context_ids': tensor([[4556, 2625,  547,  ..., 3321,  404, 2429],\n",
            "        [ 373,   81, 4350,  ..., 4107, 4939,  810],\n",
            "        [2598, 2521, 4973,  ...,  436, 3564, 4573],\n",
            "        ...,\n",
            "        [2278, 3767, 2648,  ..., 3513, 1192, 2440],\n",
            "        [ 551, 2864, 2046,  ..., 3662,  821, 3020],\n",
            "        [4573, 3491,  263,  ...,  600, 1339, 3957]])}\n",
            "Word IDs: tensor([ 2127,  2428, 10418,  1997,  9066,  1996, 24653,  2009,  1037,  3616,\n",
            "         1012,  1996,  1010,  2017,  1026, 13446,  2142,  2068,  2051,  2105,\n",
            "         3248,  2031,  2059,  1005,  1996,  7987,  4511,  2389, 16266,  1037,\n",
            "         1998,  3550])\n",
            "Positive Context: tensor([[ 2054,  2016,  2758,  1010,  2030,  2130,  4209,  2054,  2016,  2758,\n",
            "          2016,  2758,  2009,  1012,  2016,  3662,  2053, 10218,  7603,  2012],\n",
            "        [ 2009,  2515,  2272,  2041,  1997,  2187,  2492,  1010,  1998,  3475,\n",
            "          1005,  1056,  2054,  2017,  1005,  2128,  8074,  1012,  2021,     0],\n",
            "        [ 3459,  1010, 21688,  3257,  1010,  1998,  1010,  3383,  1010,  1996,\n",
            "          2143,  3556,  2412,  2517,  1010,  2191,  1000,  5102,  2000,  3102],\n",
            "        [ 2100,  9378,  2100,  6456,  2158,  1012,  1037,  2613,  2919,  2544,\n",
            "          1037,  6456,  2158,  1012,  1998,  2002,  4152,  2920,  2007,  4531],\n",
            "        [ 4556,  2189, 20305,  2097,  2053,  4797,  6709,  1996,  2189,  1996,\n",
            "          2015,  2024,  2652,  1012, 19643,  2059, 13675, 27174,  1010,  1000],\n",
            "        [ 1996,  4184,  7905, 21363,  1011,  2002,  2003,  2667,  2000,  2202,\n",
            "          2252,  2058,  1998,  2735,  2009,  2046,  1037,  1000, 11662,  3698],\n",
            "        [ 2000,  2131,  2046,  1996,  2250,  2486,  2914,  1010,  9530,  3401,\n",
            "          1997,  1037,  5436,  1006,  2007,  2393,  2013,  2010,  2128,  7559],\n",
            "        [ 2025,  2019,  8052,  2028,  1012,  2085,  2008,  1045,  2031,  2464,\n",
            "          2153,  2007,  2070,  2814,  2006,  4966,  1006,  2027,  2018,  2025],\n",
            "        [ 6749,  2005,  2111,  2559,  2005,  1037,  3835,  2210,  6172,  2007,\n",
            "          2200,  3835,  3407,  4566,  1012,     0,     0,     0,     0,     0],\n",
            "        [ 2435,  2019,  5151,  2836,  2007,  7564,  1997,  3153,  1998,  3315,\n",
            "          1012,  6506,  9413, 13153,  1010,  1006, 16123,  7867,  1007,  2435],\n",
            "        [ 7539,  1010,  1045,  2293,  1996, 17841,  3512,  4022,  2009,  2038,\n",
            "          2673,  1998,  3071,  1999,  4698,  1005,  1055,  1006,  2209,  2011],\n",
            "        [ 2358, 24388,  9513,  1000, 18201,  2008,  4300,  4740,  2000, 20432,\n",
            "         15577,  5467,  2007,  1012,  1026,  7987,  1013,  1028,  1026,  7987],\n",
            "        [ 2838,  1012,  1012,  1012,  2138,  2045,  2020,  2053,  6450,  4520,\n",
            "         12703,  1010,  2030,  2152,  1011, 21125,  3185,  3340,  1012,  1026],\n",
            "        [ 2907,  1996,  4378,  1998,  3561,  2007, 13764,  8649,  2015,  2029,\n",
            "          2052,  2031,  2657,  1037,  2454,  2335,  2077,  1012,  2028,  1997],\n",
            "        [16006,  1000,  1999,  1996,  2694, 12661,  1026,  7987,  1013,  1028,\n",
            "          7987,  1013,  1028,  2122,  2024,  2070,  1997,  1996,  2307,  4895],\n",
            "        [ 2002,  1004,  2010, 14711,  5630,  2000,  2907,  1996,  2972,  3345,\n",
            "          2061,  2027,  2064,  2031,  2019,  8917,  2100,  2007, 24696,  1004],\n",
            "        [ 1997,  2023,  2143,  1011, 15587,  1012,  2320,  2067,  1999,  1996,\n",
            "          2163,  2016,  2003,  2025,  5204,  2008,  2016,  2071,  2022,  9359],\n",
            "        [ 1012,  2005,  3183, 11867, 20051,  3334,  2730,  2370,  1010,  4292,\n",
            "          2039,  2000,  2202,  1996,  7499,  2061,  2002,  2071,  2468,  1996],\n",
            "        [ 2216, 21877,  5874, 26650,  2015,  1012,  1012,  1012,  2021,  2023,\n",
            "          2105,  2009,  1005,  1055,  9442,  1998,  2062, 21699,  1012,  1996],\n",
            "        [ 1012, 25212,  2099,  1010,  1045,  2812, 25516,  2015,  2108,  7671,\n",
            "          2006,  5793, 14666,  1007,  1010,  6649,  9188,  1999,  7982,  1010],\n",
            "        [ 3881,  6287,  5974,  2402,  9079,  2204,  2075,  1010,  2040,  5829,\n",
            "          1999,  2007, 22344,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [ 7437, 10554,  2652,  1037,  7743,  1024,  1037,  2839,  2040,  2453,\n",
            "          2042,  8282,  2521, 10524,  2322,  2086,  2077,  1007,  1010,  2008],\n",
            "        [ 2037,  3317,  1010,  2383,  4689,  3348,  2007,  2068,  1010,  1998,\n",
            "          5983,  2068,  1006,  3272,  1996,  2034,  6778,  1010,  2040,  2027],\n",
            "        [ 5458,  1997,  1996,  1000,  4286, 11891,  1000, 18856, 17322,  2008,\n",
            "          1055,  2430,  2000,  2296,  3185,  1012,  1045,  2113,  2017,  2064],\n",
            "        [ 2000,  3422,  1037,  3185,  2008,  2003,  2667,  2000,  4167, 28556,\n",
            "         11678,  1012,  2092,  2023,  2003,  1996,  4060,  1997,  1996, 19070],\n",
            "        [ 2009,  7796,  2015,  2019,  2809,  2041,  1997,  2184,  1012,  1026,\n",
            "          1013,  1028,  1026,  7987,  1013,  1028,  1996,  3276,  2090,  2257],\n",
            "        [ 1999,  1996,  2168,  2126,  2019,  6450,  1010,  2152,  3737,  2413,\n",
            "          2515,  1012,  2009,  3727,  2017,  2007,  1037,  2200,  2986,  2044],\n",
            "        [ 2925, 12773,  2395, 12406,  5206, 15487,  1998,  5469,  2143,  2358,\n",
            "         18367, 10768, 17460,  2089,  2638,  1006,  2652,  1037,  2016,  5480],\n",
            "        [ 7110,  1005,  1056,  4276,  1037,  2298,  1024,  1996,  1005,  4086,\n",
            "         14691,  2532,  1005,  2193,  3794,  2327,  3238,  7165,  3057,  2003],\n",
            "        [ 1000,  4628,  1024,  1000,  2469,  1010,  1045,  2064,  3298,  2005,\n",
            "          2096,  1012,  1000,  1006,  2320,  2766,  2058,  1010,  1996,  4062],\n",
            "        [ 2004,  1037, 10170,  1010,  1037,  5268,  1005,  1055,  5268,  1010,\n",
            "          1037,  8235, 19717,  2937,  1999,  1996,  2492,  1997, 23387,  8309],\n",
            "        [ 2469,  1010,  1996,  2381,  1999,  2023,  3185,  2001,  1000,  5365,\n",
            "          1000,  1011,  1011,  2021,  2009,  1005,  1055,  2521,  2013,  2108]])\n",
            "Negative Context: tensor([[4556, 2625,  547,  ..., 3321,  404, 2429],\n",
            "        [ 373,   81, 4350,  ..., 4107, 4939,  810],\n",
            "        [2598, 2521, 4973,  ...,  436, 3564, 4573],\n",
            "        ...,\n",
            "        [2278, 3767, 2648,  ..., 3513, 1192, 2440],\n",
            "        [ 551, 2864, 2046,  ..., 3662,  821, 3020],\n",
            "        [4573, 3491,  263,  ...,  600, 1339, 3957]])\n"
          ]
        }
      ],
      "source": [
        "i = 0\n",
        "for batch_data in train_loader:\n",
        "    print(f\"R = {R}, K = {K}\")\n",
        "    print(batch_data)\n",
        "    #print(f\"Word IDs shape: {batch['word_id'].shape}\")\n",
        "    #print(f\"Positive Context IDs shape: {batch['positive_context_ids'].shape}\")\n",
        "    #print(f\"Negative Context IDs shape: {batch['negative_context_ids'].shape}\")\n",
        "    print(\"Word IDs:\", batch_data['word_id'])\n",
        "    print(\"Positive Context:\", batch_data['positive_context_ids'])\n",
        "    print(\"Negative Context:\", batch_data['negative_context_ids'])\n",
        "    i+=1\n",
        "    if i == 2:\n",
        "      break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q9\n",
        "\n"
      ],
      "metadata": {
        "id": "a1euf5ZN6Ai-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Word2Vec(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim):\n",
        "        super(Word2Vec, self).__init__()\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.context_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    def forward(self, word_id, pos_context_ids, neg_context_ids):\n",
        "        word_embed = self.word_embeddings(word_id)\n",
        "        pos_context_embed = self.context_embeddings(pos_context_ids)\n",
        "        neg_context_embed = self.context_embeddings(neg_context_ids)\n",
        "        pos_dot_product = torch.bmm(pos_context_embed, word_embed.unsqueeze(2)).squeeze(2)\n",
        "\n",
        "        neg_dot_product = torch.bmm(neg_context_embed, word_embed.unsqueeze(2)).squeeze(2)\n",
        "\n",
        "        pos_similarity = torch.sigmoid(pos_dot_product)  # (batch_size, 2R)\n",
        "        neg_similarity = torch.sigmoid(neg_dot_product)  # (batch_size, 2R * K)\n",
        "\n",
        "        pos_loss = -torch.log(pos_similarity + 1e-8).sum(1)  # Sum over all positive contexts\n",
        "        neg_loss = -torch.log(1 - neg_similarity + 1e-8).sum(1)  # Sum over all negative contexts\n",
        "        loss = pos_loss + neg_loss\n",
        "\n",
        "        return loss.mean()"
      ],
      "metadata": {
        "id": "0CnWBfWH6EnP"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q10"
      ],
      "metadata": {
        "id": "V5fWaXJ1SSYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, E, epochs, lr =0.001):\n",
        "    model = Word2Vec(vocab_size=n_samples, embedding_dim=E)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for batch in train_loader:\n",
        "            word_id = batch['word_id']\n",
        "            positive_context_ids = batch['positive_context_ids']\n",
        "            negative_context_ids = batch['negative_context_ids']\n",
        "\n",
        "            word_id = word_id.clamp(0, vocab_size - 1) # Clip to the range [0, vocab_size-1]\n",
        "            positive_context_ids = positive_context_ids.clamp(0, vocab_size - 1)\n",
        "            negative_context_ids = negative_context_ids.clamp(0, vocab_size - 1)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss = model(word_id, positive_context_ids, negative_context_ids)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {avg_loss:.4f}')\n"
      ],
      "metadata": {
        "id": "fjXBIuNKSPme"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameters\n",
        "vocab_size = n_samples  # Size of the vocabulary\n",
        "embedding_dim = 100  # Dimension of the word embeddings\n",
        "batch_size = 64  # Batch size (B)\n",
        "epochs = 10  # Number of epochs (E)\n",
        "\n",
        "# Create the Word2Vec model\n",
        "model = Word2Vec(vocab_size, embedding_dim)\n",
        "\n",
        "# Assuming `train_dataset` is already prepared\n",
        "# Train the model\n",
        "train_model(model,train_loader, embedding_dim, epochs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQirp6JVTN_j",
        "outputId": "61252970-562a-460f-c0cc-0cf528e24c91"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 63.3057\n",
            "Epoch [2/10], Loss: 20.7194\n",
            "Epoch [3/10], Loss: 19.3998\n",
            "Epoch [4/10], Loss: 19.0619\n",
            "Epoch [5/10], Loss: 18.9144\n",
            "Epoch [6/10], Loss: 18.8256\n",
            "Epoch [7/10], Loss: 18.7714\n",
            "Epoch [8/10], Loss: 18.7369\n",
            "Epoch [9/10], Loss: 18.7125\n",
            "Epoch [10/10], Loss: 18.6827\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q11"
      ],
      "metadata": {
        "id": "adqTK1ekjyVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def validate_word2vec(model, test_loader, R, K, B): # updated here\n",
        "    \"\"\"\n",
        "    Validates the Word2Vec model on a test set by checking how well\n",
        "    the embeddings of words align with their positive and negative contexts.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): The trained Word2Vec model.\n",
        "        test_loader (torch.utils.data.DataLoader): The test data loader. # updated here\n",
        "        R (int): Radius of the context window.\n",
        "        K (int): Number of negative samples per positive context word.\n",
        "        B (int): Batch size.\n",
        "\n",
        "    Returns:\n",
        "        float: The average cosine similarity for positive contexts (C+).\n",
        "        float: The average cosine similarity for negative contexts (C-).\n",
        "    \"\"\"\n",
        "\n",
        "    # test_loader = DataLoader(test_dataset, batch_size=B, shuffle=False, collate_fn=lambda batch: collate_fn(batch, R, K)) # removed this line\n",
        "\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    total_pos_sim = 0\n",
        "    total_neg_sim = 0\n",
        "    pos_count = 0\n",
        "    neg_count = 0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation for validation\n",
        "        for batch in test_loader:\n",
        "            word_id = batch['word_id']\n",
        "            positive_context_ids = batch['positive_context_ids']\n",
        "            negative_context_ids = batch['negative_context_ids']\n",
        "\n",
        "            # Ensure word indices are within the valid vocabulary range\n",
        "            word_id = word_id.clamp(0, model.word_embeddings.num_embeddings - 1) # Clip to the range [0, vocab_size-1]\n",
        "            positive_context_ids = positive_context_ids.clamp(0, model.context_embeddings.num_embeddings - 1)\n",
        "            negative_context_ids = negative_context_ids.clamp(0, model.context_embeddings.num_embeddings - 1)\n",
        "\n",
        "            # Get embeddings for words, positive contexts, and negative contexts\n",
        "            word_embeddings = model.word_embeddings(word_id)\n",
        "            positive_embeddings = model.context_embeddings(positive_context_ids)\n",
        "            negative_embeddings = model.context_embeddings(negative_context_ids)\n",
        "\n",
        "            # Cosine similarity for positive contexts\n",
        "            pos_similarity = F.cosine_similarity(word_embeddings.unsqueeze(1), positive_embeddings, dim=-1)\n",
        "            total_pos_sim += pos_similarity.sum().item()\n",
        "            pos_count += pos_similarity.numel()\n",
        "\n",
        "            # Cosine similarity for negative contexts\n",
        "            neg_similarity = F.cosine_similarity(word_embeddings.unsqueeze(1), negative_embeddings, dim=-1)\n",
        "            total_neg_sim += neg_similarity.sum().item()\n",
        "            neg_count += neg_similarity.numel()\n",
        "\n",
        "    # Average cosine similarities\n",
        "    avg_pos_sim = total_pos_sim / pos_count\n",
        "    avg_neg_sim = total_neg_sim / neg_count\n",
        "\n",
        "    print(f\"Avg Positive Context Similarity: {avg_pos_sim:.4f}\")\n",
        "    print(f\"Avg Negative Context Similarity: {avg_neg_sim:.4f}\")\n",
        "\n",
        "    return avg_pos_sim, avg_neg_sim"
      ],
      "metadata": {
        "id": "JCh6pa7eT5Qk"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_pos_sim, avg_neg_sim = validate_word2vec(model, valid_loader, R, K, batch_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqArdcanBo62",
        "outputId": "4d0125e9-9753-4e1d-962c-9605f2f50315"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Avg Positive Context Similarity: 0.0006\n",
            "Avg Negative Context Similarity: 0.0003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q12"
      ],
      "metadata": {
        "id": "y_r7LTItj_aV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " d = n_samples\n",
        " torch.save(model.state_dict(), f\"model_dim-{d}_radius-{R}_ratio-{K}_batch-{batch_size}_epoch-{epochs}.ckpt\")"
      ],
      "metadata": {
        "id": "v29OfbKtjsaa"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "R44FQZg6kRaF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "61d0c45c257147749c9d0a7090215da1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a55353b8096d4874a2c61a80340c3ba5",
              "IPY_MODEL_003870b6e3824270a426c062fa886bb7",
              "IPY_MODEL_fd27a2c4c87a499d8ab03d9c6bd9e5ca"
            ],
            "layout": "IPY_MODEL_b35572a5c60e457bbf8f600c338c7281"
          }
        },
        "a55353b8096d4874a2c61a80340c3ba5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_219a5818da6c4475828d1aafc83cbfad",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_34a1df99e1874618a5365700b9825572",
            "value": "Map:â€‡100%"
          }
        },
        "003870b6e3824270a426c062fa886bb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d32760228abd417d88061cc0fcb84e11",
            "max": 5000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a42dc528fb2742c385803de38bcab1b8",
            "value": 5000
          }
        },
        "fd27a2c4c87a499d8ab03d9c6bd9e5ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e39e03b350947058a8e15e72c30df55",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ac6298a6a68a40989ed43b8c7afd4b9f",
            "value": "â€‡5000/5000â€‡[00:39&lt;00:00,â€‡154.26â€‡examples/s]"
          }
        },
        "b35572a5c60e457bbf8f600c338c7281": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "219a5818da6c4475828d1aafc83cbfad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34a1df99e1874618a5365700b9825572": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d32760228abd417d88061cc0fcb84e11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a42dc528fb2742c385803de38bcab1b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e39e03b350947058a8e15e72c30df55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac6298a6a68a40989ed43b8c7afd4b9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}