{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BXpR1XE6hO0O"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers datasets tabulate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JwKtGkyogSmn"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from torch.utils.data import DataLoader\n",
        "from tabulate import tabulate\n",
        "from datasets import load_dataset\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from transformers import BertTokenizer\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCdfPYKRgSmo"
      },
      "source": [
        "This is a template of the notebook that you should complete and enrich with your own code.\n",
        "\n",
        "First cells will be the same than the ones of the lab on text convolution.\n",
        "\n",
        "# Data loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TdwlJJ1gSmp",
        "outputId": "741fda47-d76f-4080-bd78-2bb909cd1bc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset({\n",
            "    features: ['review', 'sentiment'],\n",
            "    num_rows: 50000\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "dataset = load_dataset(\"scikit-learn/imdb\", split=\"train\")\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0FUMHZ3g72D"
      },
      "source": [
        "# Pre-processing / Tokenization\n",
        "\n",
        "This is a very important step. It maybe boring but very important. In this session we will be lazy, but in real life, the time spent on inspecting and cleaning data is never wasted. It is true for text, but also for everything.\n",
        "\n",
        "\n",
        "\n",
        "In PyTorch, everything is tensor. Words are replaced by indices. A sentence, is therefore a sequence of indices (long integers). In the first HW, you constructed a `WhiteSpaceTokenizer`. Here we will use an already built tokenizer. It is more appropriate to transformers. It relies on sub-word units, and converts everything in lower case. This is not always the best choice, but here it will be sufficient. To quote the documentation, this tokenizer allows you to:\n",
        "- Tokenize (splitting strings in sub-word token strings), converttokens strings to ids and back, and encoding/decoding (i.e., tokenizing and converting to integers).\n",
        "- Add new tokens to the vocabulary in a way that is independent of the underlying structure (BPE, SentencePieceâ€¦).\n",
        "- Manage special tokens (like mask, beginning-of-sentence, etc.): adding them, assigning them to attributes in the tokenizer for easy access and making sure they are not split during tokenization.\n",
        "\n",
        "Here we are going to use the tokenizer from the well known Bert model, that we can directly download."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fhCY2FygSmr",
        "outputId": "0461da13-7225-49a2-badf-80f04efa316a"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JkUifAjngSms"
      },
      "outputs": [],
      "source": [
        "def preprocessing_fn(x, tokenizer):\n",
        "    x[\"review_ids\"] = tokenizer(\n",
        "        x[\"review\"],\n",
        "        add_special_tokens=False,\n",
        "        truncation=True,\n",
        "        max_length=256,\n",
        "        padding=False,\n",
        "        return_attention_mask=False,\n",
        "    )[\"input_ids\"]\n",
        "    x[\"label\"] = 0 if x[\"sentiment\"] == \"negative\" else 1\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[100]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer(\n",
        "        \"[UNK] \",\n",
        "        add_special_tokens=False,\n",
        "        truncation=True,\n",
        "        max_length=256,\n",
        "        padding=False,\n",
        "        return_attention_mask=False,\n",
        "    )[\"input_ids\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7uhbzZngSmt"
      },
      "source": [
        "Same celel than in the lab session.\n",
        "\n",
        "ðŸš§ **TODO** ðŸš§\n",
        "\n",
        "Read the documentation about HuggingFace dataset and complete the code below.\n",
        "You should:\n",
        "- Shuffle the dataset\n",
        "- For computational reasons, use only a total of **5000 samples**.\n",
        "- Tokenize the dataset with the `preprocessing_fn`. (*Hint: use the `Dataset.map` method from HuggingFace*).\n",
        "- Keep only columns `review_ids` and `label`.\n",
        "- Make a train/validation split, (**80% / 20%**). Call these dataset `train_set` and `valid_set`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lcp_ecU14bRP"
      },
      "source": [
        "## Q1 - Tokenize and Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "61d0c45c257147749c9d0a7090215da1",
            "a55353b8096d4874a2c61a80340c3ba5",
            "003870b6e3824270a426c062fa886bb7",
            "fd27a2c4c87a499d8ab03d9c6bd9e5ca",
            "b35572a5c60e457bbf8f600c338c7281",
            "219a5818da6c4475828d1aafc83cbfad",
            "34a1df99e1874618a5365700b9825572",
            "d32760228abd417d88061cc0fcb84e11",
            "a42dc528fb2742c385803de38bcab1b8",
            "1e39e03b350947058a8e15e72c30df55",
            "ac6298a6a68a40989ed43b8c7afd4b9f"
          ]
        },
        "id": "MGNbn0IxgSmu",
        "outputId": "de26f37c-44a1-4016-8ccb-b4c2474e08e3"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01bf3713d7934df4a1dcb6cdd7720a3c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "n_samples = 50000  # the number of training example\n",
        "\n",
        "# We first shuffle the data !\n",
        "data_shuffled = dataset.shuffle()\n",
        "\n",
        "# Select 5000 samples\n",
        "data_shuffled_sampled = data_shuffled.select(range(n_samples))\n",
        "\n",
        "# Tokenize the dataset\n",
        "data_tokenized = data_shuffled_sampled.map(lambda x: preprocessing_fn(x, tokenizer))\n",
        "\n",
        "# Remove useless columns\n",
        "data_tokenized = data_tokenized.remove_columns([\"review\", \"sentiment\"])\n",
        "\n",
        "# Split the train and validation\n",
        "split = data_tokenized.train_test_split(test_size=0.2)\n",
        "train_set = split['train']\n",
        "valid_set = split[\"test\"]\n",
        "\n",
        "document_train_set = train_set[\"review_ids\"]\n",
        "document_valid_set = valid_set[\"review_ids\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_l9gdqNN4iyp"
      },
      "source": [
        "## Q2 -  Make Positive context with padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ylKpnv_MvBnm"
      },
      "outputs": [],
      "source": [
        "def extract_words_contexts(document, radius, pad_token_id=0):\n",
        "    words = []\n",
        "    contexts = []\n",
        "    \n",
        "    for i in range(len(document)):\n",
        "        words.append(document[i])\n",
        "        \n",
        "        # Create context\n",
        "        context = []\n",
        "        for j in range(i - radius, i + radius + 1):\n",
        "            if j != i:  # Exclude the word itself\n",
        "                if 0 <= j < len(document):\n",
        "                    context.append(document[j])\n",
        "                else:\n",
        "                    # Handling borders: pad with pad_token_id (usually 0 for BERT)\n",
        "                    context.append(pad_token_id)\n",
        "        \n",
        "        contexts.append(context)\n",
        "    \n",
        "    return words, contexts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mhyjUID4tAg"
      },
      "source": [
        "## Q3 Apply to dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Im7E1Xe4yzBQ"
      },
      "outputs": [],
      "source": [
        "def flatten_dataset_to_list(dataset, R):\n",
        "    all_ids = []\n",
        "    all_contexts = []\n",
        "\n",
        "    for document in tqdm(dataset):\n",
        "        ids, contexts = extract_words_contexts(document, R)\n",
        "        all_ids.extend(ids)\n",
        "        all_contexts.extend(contexts)\n",
        "\n",
        "    return all_ids, all_contexts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "u2pW_Gqp2tfv"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "971b92017f754f7aac1f0ab24b6746db",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "data_tokenized_flattened = flatten_dataset_to_list(data_tokenized[\"review_ids\"], 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGkHPrVM44C5"
      },
      "source": [
        "# Q4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "R,K = 10,5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "IKO9rmDYzyO_"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "264b0b642a894b898fc77b6f7488cc22",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/8000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1ab4e45fe614f7cb87e32b4617329d6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train_ids, train_context = flatten_dataset_to_list(document_train_set, R)\n",
        "valid_ids, valid_context = flatten_dataset_to_list(document_valid_set, R)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bpgCoWP48WW"
      },
      "source": [
        "# Q5 - Context Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "qCarhSvW0qbm"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class ContextDataset(Dataset):\n",
        "    def __init__(self, words, contexts):\n",
        "      self.words = words\n",
        "      self.contexts = contexts\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.words)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        return self.words[idx], self.contexts[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Oq1ET5oB2ry1"
      },
      "outputs": [],
      "source": [
        "train_set = ContextDataset(train_ids, train_context)\n",
        "valid_set = ContextDataset(valid_ids, valid_context)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obUP4qHwHoJD"
      },
      "source": [
        "# Q6 - Negative Context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "j28tV4sxN8pA"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch, vocab_size, K):\n",
        "    word_ids = []\n",
        "    positive_context_ids = []\n",
        "    negative_context_ids = []\n",
        "\n",
        "    for word_id, pos_context in batch:\n",
        "        word_ids.append(word_id)\n",
        "        positive_context_ids.append(pos_context)\n",
        "        \n",
        "        # Generate negative context by random sampling\n",
        "        neg_context_size = 2 * len(pos_context) * K\n",
        "        neg_context = np.random.randint(0, vocab_size, size=neg_context_size).tolist()\n",
        "        negative_context_ids.append(neg_context)\n",
        "\n",
        "    return {\n",
        "        'word_id': torch.tensor(word_ids, dtype=torch.long),\n",
        "        'positive_context_ids': torch.tensor(positive_context_ids, dtype=torch.long),\n",
        "        'negative_context_ids': torch.tensor(negative_context_ids, dtype=torch.long)\n",
        "    }\n",
        "\n",
        "vocab_size = tokenizer.vocab_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFX4Buv1Hz4M"
      },
      "source": [
        "# Q7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "gOSxHemhJ-99"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_set, batch_size=32, shuffle=True, collate_fn=lambda x: collate_fn(x, vocab_size=vocab_size, K=K))\n",
        "valid_loader = DataLoader(valid_set, batch_size=32, shuffle=False, collate_fn=lambda x: collate_fn(x, vocab_size=vocab_size, K=K))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-Iu33Ur503h"
      },
      "source": [
        "# Q8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "9C31Spk1H8HT",
        "outputId": "bcd7974f-27bf-43ec-b9d2-d671cb1c725c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'word_id': tensor([ 2003,  2031,  2471,  2009,  1010,  2143,  1012,  2147,  3510,  2002,\n",
              "          2135,  2022,  1998,  1010,  8840,  2323,  2228,  2682,  2040,  3993,\n",
              "          1012,  1044,  1012,  1037,  1056,  2031,  3849, 15338,  2143,  1005,\n",
              "         17567,  4931]),\n",
              " 'positive_context_ids': tensor([[ 5886, 10127,  1029,  6684,  2151,  1012,  2021,  7804, 20296,  2121,\n",
              "           3376,  1012,     0,     0,     0,     0,     0,     0,     0,     0],\n",
              "         [ 2044,  1037,  2096,  2017,  1005,  2222,  2593,  2025,  2729,  2030,\n",
              "           5357,  6680,  1012,  2012,  2151,  3446,  1010,  2023,  2038,  7564],\n",
              "         [ 1010,  1006,  2011,  2008,  1045,  2812,  2008,  2027,  1005,  2128,\n",
              "           1996,  2168,  3924,  1010,  2029,  2003,  1037,  2978,  1997,  1037],\n",
              "         [ 2016,  3248,  2117, 15888,  2000,  2877,  2158,  4702, 21213,  1012,\n",
              "           1005,  1055,  1037, 12063,  1010,  2138,  2016,  2038,  2062,  2895],\n",
              "         [ 2019,  9643,  2135, 11771,  1010, 15703,  1998,  3168,  3238, 10231,\n",
              "           2007, 11758,  1998, 18217,  1012,  1996, 10047,  4783,  6895,  2571],\n",
              "         [ 9811,  2008,  2204,  7497, 16021,  1005,  1056,  2590,  1999,  1996,\n",
              "           1011,  2437,  2832,  1010,  1998, 10236,  2009,  2039,  2104,  1996],\n",
              "         [ 1997,  1996,  2143,  1010,  2174,  1010,  2008,  2001,  2055,  2009,\n",
              "           2302,  2130,  3241,  1045,  2354,  2073,  1996,  5436,  2052,  2022],\n",
              "         [ 2621,  4518,  1012,  2065,  2017,  1005,  2310,  2412,  2589,  2151,\n",
              "           1999,  3004,  1011,  2926,  2012,  1037,  2621,  4518,  3004,  1011],\n",
              "         [ 2008,  1996,  3203,  2013,  8344,  2001,  2108,  2081,  1010,  1996,\n",
              "           1997, 25026, 23447,  1998, 11620, 10974,  5172,  2001,  4487, 11493],\n",
              "         [ 3968, 16216,  2378,  2106,  2025, 16582, 27756,  1999,  2270,  1010,\n",
              "           2001,  2200,  5475,  1998,  5067,  1998,  2467,  5186, 13205,  2000],\n",
              "         [    0,  1045,  2031,  2000,  2360,  2008,  2023,  2143,  2001,  6581,\n",
              "           2550,  1998, 13284,  1996,  8599,  2004,  1037,  5171, 16596, 10882],\n",
              "         [ 2048,  3287,  2814,  1006,  1045,  2245,  2016,  2001,  4011,  2000,\n",
              "           9479,  1029,  1007,  2000,  2707,  2635,  5850,  1012,  2821,  3532],\n",
              "         [ 1013,  1028,  1000,  4439,  8220,  1000,  2003,  2170,  1996,  7157,\n",
              "          21696,  2063,  1997,  2023,  4245,  2007, 14641,  5861,  2102,  2652],\n",
              "         [ 2017,  9422,  1029,  2023,  3185,  1010,  2096, 14013,  2135, 14036,\n",
              "           2003,  9643,   999,  1026,  7987,  1013,  1028,  1026,  7987,  1013],\n",
              "         [ 1012,  2044,  1996,  9916,  2306,  2014, 21233,  2024,  5462,  1010,\n",
              "          12789,  8300,  3619, 24683,  1010,  2411,  9789,  3238,  2004,  2000],\n",
              "         [ 2204,  1999,  2049,  2219,  2126,  1010,  2021,  2067,  2059,  1045,\n",
              "           2031,  8615,  1037,  8297,  1012,  1026,  7987,  1013,  1028,  1026],\n",
              "         [ 1037,  2061,  1011,  2170, 12934, 27417, 18219,  1010,  2348,  1045,\n",
              "           1996,  8476,  2003,  2205,  3809,  2655,  2009,  2066,  2008,  1012],\n",
              "         [ 2054,  2027,  2106,  1029,  1011,  1011,  2054,  2035,  1997,  1996,\n",
              "           6083,  2003,  2008,  1996,  2516,  2003,  4415,  3214,  2000,  6523],\n",
              "         [ 1017,  1996,  3015,  2150,  3811,  3375,  1012,  2005,  6013,  1010,\n",
              "           2003,  6213,  1029,  2339,  2024,  2045, 11508,  6468,  2006,  1996],\n",
              "         [ 1012,  1045,  2903,  2008,  1996,  2685,  2017,  2081,  2020, 12369,\n",
              "           1010,  9414,  1998,  6135,  9398,  1012,  2009,  1005,  1055,  2036],\n",
              "         [ 5875,  2069,  1999,  1996,  2755,  2008,  2009,  2001,  2941,  2081,\n",
              "           8472,  7570, 20791,  1005,  1055, 13954,  1997,  3968, 16216,  2378],\n",
              "         [ 2008,  5353,  2362,  2725,  3599,  2054,  1996,  3626,  2079,  1999,\n",
              "           2102,  1012,  2057,  2073,  2746,  2091,  2096,  2057,  3427,  1998],\n",
              "         [ 1012,  1045,  5136,  1037,  2143,  9637,  1997,  2086,  1005,  3963,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
              "         [ 2049,  7863,  2003,  1999,  1037, 14202,  4942, 24759,  4140,  5994,\n",
              "           3232,  1997,  4654,  1011,  9530,  2015,  2040,  2031,  2358, 11823],\n",
              "         [ 1010,  2002,  2134,  1005,  1056,  1012,  2061,  2009,  2134,  1005,\n",
              "           6293,  2007,  2009,  1010,  1996, 25506,  1012,  1026,  7987,  1013],\n",
              "         [ 5690,  2091,  1996,  6359,  1006,  5667,  2002,  2987,  1005,  1056,\n",
              "           1037,  2171,  1010,  2002,  1005,  1055,  2074,  1996,  6359,  1007],\n",
              "         [ 1012,  1026,  7987,  1013,  1028,  1026,  7987,  1013,  1028,  2009,\n",
              "          10021,  2008,  1037,  2466,  2055, 27754,  1998,  1037,  2158,  2992],\n",
              "         [ 2005,  2028,  1997,  2122, 27243, 12934, 27417, 18219, 28616,  4215,\n",
              "          14900,  1010,  2007,  1037,  6565,  9140,  1997,  2381,  1998,  5722],\n",
              "         [ 2015,  1010,  2191,  2053,  6707,  2055,  2009,  2023,  2003,  1037,\n",
              "           2035,  2055,  4126,  1999,  1996,  3770,  1005,  1055,  1998,  2096],\n",
              "         [ 2128,  5110, 18847, 24277,  2030, 21283,  1010,  2029,  2027,  4995,\n",
              "           1056,  1012,  2007,  1996,  5508,  1997,  2158,  2618, 16989,  2477],\n",
              "         [ 1005,  2214,  1005,  3626,  2732, 10313,  3152,  1010,  2023,  2143,\n",
              "           2013,  2019,  9643,  5896,  1998,  5793,  5166, 14679,  1010,  3391],\n",
              "         [ 1028,  1026,  7987,  1013,  1028,  2045,  1005,  1055,  1037,  1000,\n",
              "           4268,  1010,  2292,  1005,  1055,  2404,  2006,  1037,  2265,  2250]]),\n",
              " 'negative_context_ids': tensor([[20511,  7350, 20029,  ...,  7447, 17480, 12544],\n",
              "         [10287,  6389,  6081,  ..., 10423,  8670, 17210],\n",
              "         [ 1237, 15888,  2729,  ..., 10293, 29209,  8565],\n",
              "         ...,\n",
              "         [24460, 17077,  9604,  ..., 26062, 13042, 27305],\n",
              "         [10719, 29732, 23347,  ..., 11179,   421,  5460],\n",
              "         [22790, 14898,  2032,  ..., 27468,  1812, 21681]])}"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch = next(iter(train_loader))\n",
        "batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch['word_id'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 20])"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch['positive_context_ids'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 200])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch['negative_context_ids'].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1euf5ZN6Ai-"
      },
      "source": [
        "# Q9 - Word2Vec Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "0CnWBfWH6EnP"
      },
      "outputs": [],
      "source": [
        "class Word2Vec(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim,device = 'cuda'):\n",
        "        super(Word2Vec, self).__init__()\n",
        "        self.device = device\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim).to(device)\n",
        "        self.context_embeddings = nn.Embedding(vocab_size, embedding_dim).to(device)\n",
        "\n",
        "    def forward(self, word_id, pos_context_ids, neg_context_ids):\n",
        "        word_embed = self.word_embeddings(word_id)\n",
        "        #print(\"word\",word_embed.shape)\n",
        "\n",
        "        pos_context_embed = self.context_embeddings(pos_context_ids).to(self.device)\n",
        "        #print(\"pos\",pos_context_embed.shape)\n",
        "        neg_context_embed = self.context_embeddings(neg_context_ids).to(self.device)\n",
        "        #print(\"neg\",neg_context_embed.shape)\n",
        "\n",
        "        pos_dot_product = torch.bmm(pos_context_embed, word_embed.unsqueeze(2)).squeeze(2)\n",
        "        #print(\"pos_dot_product\",pos_dot_product.shape)\n",
        "\n",
        "        neg_dot_product = torch.bmm(neg_context_embed, word_embed.unsqueeze(2)).squeeze(2)\n",
        "        #print(\"neg_dot_product\",neg_dot_product.shape)\n",
        "\n",
        "        pos_similarity = torch.sigmoid(pos_dot_product)\n",
        "        #print(\"pos_similarity\",pos_similarity.shape)  # (batch_size, 2R)\n",
        "\n",
        "        neg_similarity = torch.sigmoid(neg_dot_product)\n",
        "        #print(\"neg_similarity\",neg_similarity.shape) # (batch_size, 2R * K)\n",
        "\n",
        "        pos_loss = -torch.log(pos_similarity + 1e-8).sum(1)  # Sum over all positive contexts\n",
        "        neg_loss = -torch.log(1 - neg_similarity + 1e-8).sum(1)  # Sum over all negative contexts\n",
        "        loss = pos_loss + neg_loss\n",
        "        #print(loss.shape)\n",
        "\n",
        "        return loss.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5fWaXJ1SSYH"
      },
      "source": [
        "# Q10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "51403"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "fjXBIuNKSPme"
      },
      "outputs": [],
      "source": [
        "def train_model(model, batch_size, epochs, lr =0.001):\n",
        "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, \n",
        "        collate_fn=lambda x: collate_fn(x, vocab_size=vocab_size, K=K))\n",
        "    \n",
        "    valid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=False,\n",
        "        collate_fn=lambda x: collate_fn(x, vocab_size=vocab_size, K=K))\n",
        "    \n",
        "    print(len(train_loader))\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    device = 'cuda'\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        total_loss_val = 0\n",
        "\n",
        "        print(\"### Train\")\n",
        "\n",
        "        for batch in tqdm(train_loader):\n",
        "\n",
        "            word_id = batch['word_id'].to(device)\n",
        "            positive_context_ids = batch['positive_context_ids'].to(device)\n",
        "            negative_context_ids = batch['negative_context_ids'].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss = model(word_id, positive_context_ids, negative_context_ids)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(\"### Val\")\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(valid_loader):\n",
        "                word_id = batch['word_id'].to(device)\n",
        "                positive_context_ids = batch['positive_context_ids'].to(device)\n",
        "                negative_context_ids = batch['negative_context_ids'].to(device)\n",
        "                loss = model(word_id, positive_context_ids, negative_context_ids)\n",
        "                total_loss_val += loss.item()\n",
        "        \n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        avg_loss_val = total_loss_val / len(valid_loader)\n",
        "\n",
        "        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {avg_loss:.4f}, Val_Loss: {avg_loss_val:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define hyperparameters\n",
        "vocab_size = vocab_size  # Size of the vocabulary\n",
        "embedding_dim = 100  # Dimension of the word embeddings\n",
        "batch_size = 1024  # Batch size (B)\n",
        "epochs = 20  # Number of epochs (E)\n",
        "\n",
        "# Create the Word2Vec model\n",
        "model = Word2Vec(vocab_size, embedding_dim)\n",
        "\n",
        "# Assuming `train_dataset` is already prepared\n",
        "# Train the model\n",
        "train_model(model,batch_size, epochs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adqTK1ekjyVP"
      },
      "source": [
        "# Q11 - Cosine Similarity Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "JCh6pa7eT5Qk"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def validate_word2vec(model, test_loader, R, K, B): # updated here\n",
        "    \n",
        "    # test_loader = DataLoader(test_dataset, batch_size=B, shuffle=False, collate_fn=lambda batch: collate_fn(batch, R, K)) # removed this line\n",
        "\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    total_pos_sim = 0\n",
        "    total_neg_sim = 0\n",
        "    pos_count = 0\n",
        "    neg_count = 0\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation for validation\n",
        "        for batch in test_loader:\n",
        "            word_id = batch['word_id'].to('cuda')\n",
        "            positive_context_ids = batch['positive_context_ids'].to('cuda')\n",
        "            negative_context_ids = batch['negative_context_ids'].to('cuda')\n",
        "\n",
        "            # Get embeddings for words, positive contexts, and negative contexts\n",
        "            word_embeddings = model.word_embeddings(word_id)\n",
        "            positive_embeddings = model.context_embeddings(positive_context_ids)\n",
        "            negative_embeddings = model.context_embeddings(negative_context_ids)\n",
        "\n",
        "            # Cosine similarity for positive contexts\n",
        "            pos_similarity = F.cosine_similarity(word_embeddings.unsqueeze(1), positive_embeddings, dim=-1)\n",
        "            total_pos_sim += pos_similarity.sum().item()\n",
        "            pos_count += pos_similarity.numel()\n",
        "\n",
        "            # Cosine similarity for negative contexts\n",
        "            neg_similarity = F.cosine_similarity(word_embeddings.unsqueeze(1), negative_embeddings, dim=-1)\n",
        "            total_neg_sim += neg_similarity.sum().item()\n",
        "            neg_count += neg_similarity.numel()\n",
        "\n",
        "    # Average cosine similarities\n",
        "    avg_pos_sim = total_pos_sim / pos_count\n",
        "    avg_neg_sim = total_neg_sim / neg_count\n",
        "\n",
        "    print(f\"Avg Positive Context Similarity: {avg_pos_sim:.4f}\")\n",
        "    print(f\"Avg Negative Context Similarity: {avg_neg_sim:.4f}\")\n",
        "\n",
        "    return avg_pos_sim, avg_neg_sim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqArdcanBo62",
        "outputId": "4d0125e9-9753-4e1d-962c-9605f2f50315"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Avg Positive Context Similarity: 0.2980\n",
            "Avg Negative Context Similarity: -0.3560\n"
          ]
        }
      ],
      "source": [
        "avg_pos_sim, avg_neg_sim = validate_word2vec(model, valid_loader, R, K, batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_r7LTItj_aV"
      },
      "source": [
        "# Q12 - Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), f\"model2_dim-{embedding_dim}_radius-{R}_ratio-{K}_batch-{batch_size}_epoch-{epochs}_samples-{n_samples}.ckpt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "R44FQZg6kRaF"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Word2Vec(\n",
              "  (word_embeddings): Embedding(30522, 100)\n",
              "  (context_embeddings): Embedding(30522, 100)\n",
              ")"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "003870b6e3824270a426c062fa886bb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d32760228abd417d88061cc0fcb84e11",
            "max": 5000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a42dc528fb2742c385803de38bcab1b8",
            "value": 5000
          }
        },
        "1e39e03b350947058a8e15e72c30df55": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "219a5818da6c4475828d1aafc83cbfad": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34a1df99e1874618a5365700b9825572": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61d0c45c257147749c9d0a7090215da1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a55353b8096d4874a2c61a80340c3ba5",
              "IPY_MODEL_003870b6e3824270a426c062fa886bb7",
              "IPY_MODEL_fd27a2c4c87a499d8ab03d9c6bd9e5ca"
            ],
            "layout": "IPY_MODEL_b35572a5c60e457bbf8f600c338c7281"
          }
        },
        "a42dc528fb2742c385803de38bcab1b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a55353b8096d4874a2c61a80340c3ba5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_219a5818da6c4475828d1aafc83cbfad",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_34a1df99e1874618a5365700b9825572",
            "value": "Map:â€‡100%"
          }
        },
        "ac6298a6a68a40989ed43b8c7afd4b9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b35572a5c60e457bbf8f600c338c7281": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d32760228abd417d88061cc0fcb84e11": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd27a2c4c87a499d8ab03d9c6bd9e5ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e39e03b350947058a8e15e72c30df55",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ac6298a6a68a40989ed43b8c7afd4b9f",
            "value": "â€‡5000/5000â€‡[00:39&lt;00:00,â€‡154.26â€‡examples/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
