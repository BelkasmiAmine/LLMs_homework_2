{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BXpR1XE6hO0O"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JwKtGkyogSmn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from torch.utils.data import DataLoader\n",
        "from tabulate import tabulate\n",
        "from datasets import load_dataset\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from transformers import BertTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rCdfPYKRgSmo"
      },
      "source": [
        "This is a template of the notebook that you should complete and enrich with your own code.\n",
        "\n",
        "First cells will be the same than the ones of the lab on text convolution.\n",
        "\n",
        "# Data loading\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TdwlJJ1gSmp",
        "outputId": "2164570f-39a8-4602-e512-6cd89a733219"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['review', 'sentiment'],\n",
            "    num_rows: 50000\n",
            "})\n"
          ]
        }
      ],
      "source": [
        "dataset = load_dataset(\"scikit-learn/imdb\", split=\"train\")\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0FUMHZ3g72D"
      },
      "source": [
        "# Pre-processing / Tokenization\n",
        "\n",
        "This is a very important step. It maybe boring but very important. In this session we will be lazy, but in real life, the time spent on inspecting and cleaning data is never wasted. It is true for text, but also for everything.\n",
        "\n",
        "\n",
        "\n",
        "In PyTorch, everything is tensor. Words are replaced by indices. A sentence, is therefore a sequence of indices (long integers). In the first HW, you constructed a `WhiteSpaceTokenizer`. Here we will use an already built tokenizer. It is more appropriate to transformers. It relies on sub-word units, and converts everything in lower case. This is not always the best choice, but here it will be sufficient. To quote the documentation, this tokenizer allows you to:\n",
        "- Tokenize (splitting strings in sub-word token strings), converttokens strings to ids and back, and encoding/decoding (i.e., tokenizing and converting to integers).\n",
        "- Add new tokens to the vocabulary in a way that is independent of the underlying structure (BPE, SentencePieceâ€¦).\n",
        "- Manage special tokens (like mask, beginning-of-sentence, etc.): adding them, assigning them to attributes in the tokenizer for easy access and making sure they are not split during tokenization.\n",
        "\n",
        "Here we are going to use the tokenizer from the well known Bert model, that we can directly download."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fhCY2FygSmr",
        "outputId": "41125c7c-79b3-496d-e36c-ba19ab8ee070"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JkUifAjngSms"
      },
      "outputs": [],
      "source": [
        "def preprocessing_fn(x, tokenizer):\n",
        "    x[\"review_ids\"] = tokenizer(\n",
        "        x[\"review\"],\n",
        "        add_special_tokens=False,\n",
        "        truncation=True,\n",
        "        max_length=256,\n",
        "        padding=False,\n",
        "        return_attention_mask=False,\n",
        "    )[\"input_ids\"]\n",
        "    x[\"label\"] = 0 if x[\"sentiment\"] == \"negative\" else 1\n",
        "    return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7uhbzZngSmt"
      },
      "source": [
        "Same celel than in the lab session.\n",
        "\n",
        "ðŸš§ **TODO** ðŸš§\n",
        "\n",
        "Read the documentation about HuggingFace dataset and complete the code below.\n",
        "You should:\n",
        "- Shuffle the dataset\n",
        "- For computational reasons, use only a total of **5000 samples**.\n",
        "- Tokenize the dataset with the `preprocessing_fn`. (*Hint: use the `Dataset.map` method from HuggingFace*).\n",
        "- Keep only columns `review_ids` and `label`.\n",
        "- Make a train/validation split, (**80% / 20%**). Call these dataset `train_set` and `valid_set`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lcp_ecU14bRP"
      },
      "source": [
        "## Q1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f33ddff77b7e492a8f87472efe1c4959",
            "e43b714ab839464a9c78388ef17852b9",
            "e22e9ef8c1ae4505af65c2959ad955b0",
            "f885886b57364ae289e9959d1b74de07",
            "f7e0bcc4071b416583042c438444de85",
            "6593b9e1678444e5b0947bf8f2e49244",
            "ff1248dd9bee4a7e83a5b02c271af9b0",
            "444c687d59da438e947fd0f92a8de494",
            "5c1af1e1884f4cd0aac50ff8303d9761",
            "beee8008bf324697830443b8113a8676",
            "0562e74db7aa4bff9018464bd022028c"
          ]
        },
        "id": "MGNbn0IxgSmu",
        "outputId": "d4395765-d890-42d8-d434-b3f1cd667aa3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f33ddff77b7e492a8f87472efe1c4959"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "n_samples = 5000  # the number of training example\n",
        "\n",
        "# We first shuffle the data !\n",
        "data_shuffled = dataset.shuffle()\n",
        "\n",
        "# Select 5000 samples\n",
        "data_shuffled_sampled = data_shuffled.select(range(n_samples))\n",
        "\n",
        "# Tokenize the dataset\n",
        "data_tokenized = data_shuffled_sampled.map(lambda x: preprocessing_fn(x, tokenizer))\n",
        "\n",
        "# Remove useless columns\n",
        "data_tokenized = data_tokenized.remove_columns([\"review\", \"sentiment\"])\n",
        "\n",
        "# Split the train and validation\n",
        "train_set = data_tokenized.train_test_split(test_size=0.2)[\"train\"]\n",
        "valid_set = data_tokenized.train_test_split(test_size=0.2)[\"test\"]\n",
        "\n",
        "document_train_set = train_set[\"review_ids\"]\n",
        "document_valid_set = valid_set[\"review_ids\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CvYwS5qevjIh",
        "outputId": "a0b33235-668f-4c0c-9270-e0f690f36ca2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'review_ids': [2023,\n",
              "  2003,\n",
              "  1037,\n",
              "  4326,\n",
              "  1010,\n",
              "  18439,\n",
              "  1010,\n",
              "  16524,\n",
              "  1010,\n",
              "  9686,\n",
              "  29112,\n",
              "  2143,\n",
              "  1012,\n",
              "  2065,\n",
              "  2045,\n",
              "  2003,\n",
              "  2107,\n",
              "  1037,\n",
              "  2518,\n",
              "  2004,\n",
              "  1000,\n",
              "  7789,\n",
              "  5469,\n",
              "  1000,\n",
              "  5988,\n",
              "  1010,\n",
              "  2023,\n",
              "  2143,\n",
              "  2003,\n",
              "  2009,\n",
              "  1012,\n",
              "  1045,\n",
              "  2318,\n",
              "  2000,\n",
              "  2131,\n",
              "  6015,\n",
              "  1998,\n",
              "  4299,\n",
              "  2045,\n",
              "  2001,\n",
              "  2619,\n",
              "  2842,\n",
              "  3666,\n",
              "  2009,\n",
              "  2007,\n",
              "  2033,\n",
              "  1010,\n",
              "  1998,\n",
              "  2009,\n",
              "  4510,\n",
              "  2038,\n",
              "  1037,\n",
              "  5436,\n",
              "  999,\n",
              "  1045,\n",
              "  1005,\n",
              "  1049,\n",
              "  2183,\n",
              "  2000,\n",
              "  2031,\n",
              "  2000,\n",
              "  2156,\n",
              "  2023,\n",
              "  2143,\n",
              "  2153,\n",
              "  3674,\n",
              "  2335,\n",
              "  2077,\n",
              "  1045,\n",
              "  2514,\n",
              "  1045,\n",
              "  2428,\n",
              "  3305,\n",
              "  2009,\n",
              "  1012,\n",
              "  2065,\n",
              "  2017,\n",
              "  1005,\n",
              "  2128,\n",
              "  1996,\n",
              "  2785,\n",
              "  1997,\n",
              "  2711,\n",
              "  2040,\n",
              "  7777,\n",
              "  1000,\n",
              "  2026,\n",
              "  4596,\n",
              "  2007,\n",
              "  7213,\n",
              "  1000,\n",
              "  1998,\n",
              "  3152,\n",
              "  2011,\n",
              "  2643,\n",
              "  4232,\n",
              "  1010,\n",
              "  2030,\n",
              "  2065,\n",
              "  2017,\n",
              "  2079,\n",
              "  1037,\n",
              "  2843,\n",
              "  1997,\n",
              "  2568,\n",
              "  1011,\n",
              "  22552,\n",
              "  5850,\n",
              "  1010,\n",
              "  2017,\n",
              "  2097,\n",
              "  2763,\n",
              "  5959,\n",
              "  2023,\n",
              "  2143,\n",
              "  1012,\n",
              "  10166,\n",
              "  1012],\n",
              " 'label': 1}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "data_tokenized[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_l9gdqNN4iyp"
      },
      "source": [
        "# Q2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ylKpnv_MvBnm"
      },
      "outputs": [],
      "source": [
        "#A revoir car les C n'ont pas toujours la mÃªme taille, pour l'instant je l'utilise pour avancer\n",
        "\n",
        "def extract_words_contexts(w, R):\n",
        "  ids = []\n",
        "  pos_con = []\n",
        "  for i in range(len(w)):\n",
        "    ids.append(w[i])\n",
        "    if i<R:\n",
        "      pos_con.append(w[0:i])\n",
        "    else:\n",
        "      pos_con.append(w[i-R:i])\n",
        "    if i>len(w)-R-1:\n",
        "      pos_con.append(w[i+1:len(w)])\n",
        "    else:\n",
        "      pos_con.append(w[i+1:i+R+1])\n",
        "    if len(pos_con)<2*R:\n",
        "      pos_con.append([0]*(2*R-len(pos_con)))\n",
        "  return ids, pos_con"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mhyjUID4tAg"
      },
      "source": [
        "# Q3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Im7E1Xe4yzBQ"
      },
      "outputs": [],
      "source": [
        "def flatten_dataset_to_list(dataset, R):\n",
        "  L=[]\n",
        "  for x in dataset:\n",
        "    L.append(extract_words_contexts(x, R))\n",
        "  return L"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "u2pW_Gqp2tfv"
      },
      "outputs": [],
      "source": [
        "data_tokenized_flattened = flatten_dataset_to_list(data_tokenized[\"review_ids\"], 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FkgwC23sk98o",
        "outputId": "8d05750f-a903-45f2-c359-d3e96981449f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([2023,\n",
              "  2003,\n",
              "  1037,\n",
              "  4326,\n",
              "  1010,\n",
              "  18439,\n",
              "  1010,\n",
              "  16524,\n",
              "  1010,\n",
              "  9686,\n",
              "  29112,\n",
              "  2143,\n",
              "  1012,\n",
              "  2065,\n",
              "  2045,\n",
              "  2003,\n",
              "  2107,\n",
              "  1037,\n",
              "  2518,\n",
              "  2004,\n",
              "  1000,\n",
              "  7789,\n",
              "  5469,\n",
              "  1000,\n",
              "  5988,\n",
              "  1010,\n",
              "  2023,\n",
              "  2143,\n",
              "  2003,\n",
              "  2009,\n",
              "  1012,\n",
              "  1045,\n",
              "  2318,\n",
              "  2000,\n",
              "  2131,\n",
              "  6015,\n",
              "  1998,\n",
              "  4299,\n",
              "  2045,\n",
              "  2001,\n",
              "  2619,\n",
              "  2842,\n",
              "  3666,\n",
              "  2009,\n",
              "  2007,\n",
              "  2033,\n",
              "  1010,\n",
              "  1998,\n",
              "  2009,\n",
              "  4510,\n",
              "  2038,\n",
              "  1037,\n",
              "  5436,\n",
              "  999,\n",
              "  1045,\n",
              "  1005,\n",
              "  1049,\n",
              "  2183,\n",
              "  2000,\n",
              "  2031,\n",
              "  2000,\n",
              "  2156,\n",
              "  2023,\n",
              "  2143,\n",
              "  2153,\n",
              "  3674,\n",
              "  2335,\n",
              "  2077,\n",
              "  1045,\n",
              "  2514,\n",
              "  1045,\n",
              "  2428,\n",
              "  3305,\n",
              "  2009,\n",
              "  1012,\n",
              "  2065,\n",
              "  2017,\n",
              "  1005,\n",
              "  2128,\n",
              "  1996,\n",
              "  2785,\n",
              "  1997,\n",
              "  2711,\n",
              "  2040,\n",
              "  7777,\n",
              "  1000,\n",
              "  2026,\n",
              "  4596,\n",
              "  2007,\n",
              "  7213,\n",
              "  1000,\n",
              "  1998,\n",
              "  3152,\n",
              "  2011,\n",
              "  2643,\n",
              "  4232,\n",
              "  1010,\n",
              "  2030,\n",
              "  2065,\n",
              "  2017,\n",
              "  2079,\n",
              "  1037,\n",
              "  2843,\n",
              "  1997,\n",
              "  2568,\n",
              "  1011,\n",
              "  22552,\n",
              "  5850,\n",
              "  1010,\n",
              "  2017,\n",
              "  2097,\n",
              "  2763,\n",
              "  5959,\n",
              "  2023,\n",
              "  2143,\n",
              "  1012,\n",
              "  10166,\n",
              "  1012],\n",
              " [[],\n",
              "  [2003, 1037, 4326, 1010, 18439, 1010, 16524, 1010, 9686, 29112],\n",
              "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "  [2023],\n",
              "  [1037, 4326, 1010, 18439, 1010, 16524, 1010, 9686, 29112, 2143],\n",
              "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "  [2023, 2003],\n",
              "  [4326, 1010, 18439, 1010, 16524, 1010, 9686, 29112, 2143, 1012],\n",
              "  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "  [2023, 2003, 1037],\n",
              "  [1010, 18439, 1010, 16524, 1010, 9686, 29112, 2143, 1012, 2065],\n",
              "  [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "  [2023, 2003, 1037, 4326],\n",
              "  [18439, 1010, 16524, 1010, 9686, 29112, 2143, 1012, 2065, 2045],\n",
              "  [0, 0, 0, 0, 0, 0],\n",
              "  [2023, 2003, 1037, 4326, 1010],\n",
              "  [1010, 16524, 1010, 9686, 29112, 2143, 1012, 2065, 2045, 2003],\n",
              "  [0, 0, 0],\n",
              "  [2023, 2003, 1037, 4326, 1010, 18439],\n",
              "  [16524, 1010, 9686, 29112, 2143, 1012, 2065, 2045, 2003, 2107],\n",
              "  [2023, 2003, 1037, 4326, 1010, 18439, 1010],\n",
              "  [1010, 9686, 29112, 2143, 1012, 2065, 2045, 2003, 2107, 1037],\n",
              "  [2023, 2003, 1037, 4326, 1010, 18439, 1010, 16524],\n",
              "  [9686, 29112, 2143, 1012, 2065, 2045, 2003, 2107, 1037, 2518],\n",
              "  [2023, 2003, 1037, 4326, 1010, 18439, 1010, 16524, 1010],\n",
              "  [29112, 2143, 1012, 2065, 2045, 2003, 2107, 1037, 2518, 2004],\n",
              "  [2023, 2003, 1037, 4326, 1010, 18439, 1010, 16524, 1010, 9686],\n",
              "  [2143, 1012, 2065, 2045, 2003, 2107, 1037, 2518, 2004, 1000],\n",
              "  [2003, 1037, 4326, 1010, 18439, 1010, 16524, 1010, 9686, 29112],\n",
              "  [1012, 2065, 2045, 2003, 2107, 1037, 2518, 2004, 1000, 7789],\n",
              "  [1037, 4326, 1010, 18439, 1010, 16524, 1010, 9686, 29112, 2143],\n",
              "  [2065, 2045, 2003, 2107, 1037, 2518, 2004, 1000, 7789, 5469],\n",
              "  [4326, 1010, 18439, 1010, 16524, 1010, 9686, 29112, 2143, 1012],\n",
              "  [2045, 2003, 2107, 1037, 2518, 2004, 1000, 7789, 5469, 1000],\n",
              "  [1010, 18439, 1010, 16524, 1010, 9686, 29112, 2143, 1012, 2065],\n",
              "  [2003, 2107, 1037, 2518, 2004, 1000, 7789, 5469, 1000, 5988],\n",
              "  [18439, 1010, 16524, 1010, 9686, 29112, 2143, 1012, 2065, 2045],\n",
              "  [2107, 1037, 2518, 2004, 1000, 7789, 5469, 1000, 5988, 1010],\n",
              "  [1010, 16524, 1010, 9686, 29112, 2143, 1012, 2065, 2045, 2003],\n",
              "  [1037, 2518, 2004, 1000, 7789, 5469, 1000, 5988, 1010, 2023],\n",
              "  [16524, 1010, 9686, 29112, 2143, 1012, 2065, 2045, 2003, 2107],\n",
              "  [2518, 2004, 1000, 7789, 5469, 1000, 5988, 1010, 2023, 2143],\n",
              "  [1010, 9686, 29112, 2143, 1012, 2065, 2045, 2003, 2107, 1037],\n",
              "  [2004, 1000, 7789, 5469, 1000, 5988, 1010, 2023, 2143, 2003],\n",
              "  [9686, 29112, 2143, 1012, 2065, 2045, 2003, 2107, 1037, 2518],\n",
              "  [1000, 7789, 5469, 1000, 5988, 1010, 2023, 2143, 2003, 2009],\n",
              "  [29112, 2143, 1012, 2065, 2045, 2003, 2107, 1037, 2518, 2004],\n",
              "  [7789, 5469, 1000, 5988, 1010, 2023, 2143, 2003, 2009, 1012],\n",
              "  [2143, 1012, 2065, 2045, 2003, 2107, 1037, 2518, 2004, 1000],\n",
              "  [5469, 1000, 5988, 1010, 2023, 2143, 2003, 2009, 1012, 1045],\n",
              "  [1012, 2065, 2045, 2003, 2107, 1037, 2518, 2004, 1000, 7789],\n",
              "  [1000, 5988, 1010, 2023, 2143, 2003, 2009, 1012, 1045, 2318],\n",
              "  [2065, 2045, 2003, 2107, 1037, 2518, 2004, 1000, 7789, 5469],\n",
              "  [5988, 1010, 2023, 2143, 2003, 2009, 1012, 1045, 2318, 2000],\n",
              "  [2045, 2003, 2107, 1037, 2518, 2004, 1000, 7789, 5469, 1000],\n",
              "  [1010, 2023, 2143, 2003, 2009, 1012, 1045, 2318, 2000, 2131],\n",
              "  [2003, 2107, 1037, 2518, 2004, 1000, 7789, 5469, 1000, 5988],\n",
              "  [2023, 2143, 2003, 2009, 1012, 1045, 2318, 2000, 2131, 6015],\n",
              "  [2107, 1037, 2518, 2004, 1000, 7789, 5469, 1000, 5988, 1010],\n",
              "  [2143, 2003, 2009, 1012, 1045, 2318, 2000, 2131, 6015, 1998],\n",
              "  [1037, 2518, 2004, 1000, 7789, 5469, 1000, 5988, 1010, 2023],\n",
              "  [2003, 2009, 1012, 1045, 2318, 2000, 2131, 6015, 1998, 4299],\n",
              "  [2518, 2004, 1000, 7789, 5469, 1000, 5988, 1010, 2023, 2143],\n",
              "  [2009, 1012, 1045, 2318, 2000, 2131, 6015, 1998, 4299, 2045],\n",
              "  [2004, 1000, 7789, 5469, 1000, 5988, 1010, 2023, 2143, 2003],\n",
              "  [1012, 1045, 2318, 2000, 2131, 6015, 1998, 4299, 2045, 2001],\n",
              "  [1000, 7789, 5469, 1000, 5988, 1010, 2023, 2143, 2003, 2009],\n",
              "  [1045, 2318, 2000, 2131, 6015, 1998, 4299, 2045, 2001, 2619],\n",
              "  [7789, 5469, 1000, 5988, 1010, 2023, 2143, 2003, 2009, 1012],\n",
              "  [2318, 2000, 2131, 6015, 1998, 4299, 2045, 2001, 2619, 2842],\n",
              "  [5469, 1000, 5988, 1010, 2023, 2143, 2003, 2009, 1012, 1045],\n",
              "  [2000, 2131, 6015, 1998, 4299, 2045, 2001, 2619, 2842, 3666],\n",
              "  [1000, 5988, 1010, 2023, 2143, 2003, 2009, 1012, 1045, 2318],\n",
              "  [2131, 6015, 1998, 4299, 2045, 2001, 2619, 2842, 3666, 2009],\n",
              "  [5988, 1010, 2023, 2143, 2003, 2009, 1012, 1045, 2318, 2000],\n",
              "  [6015, 1998, 4299, 2045, 2001, 2619, 2842, 3666, 2009, 2007],\n",
              "  [1010, 2023, 2143, 2003, 2009, 1012, 1045, 2318, 2000, 2131],\n",
              "  [1998, 4299, 2045, 2001, 2619, 2842, 3666, 2009, 2007, 2033],\n",
              "  [2023, 2143, 2003, 2009, 1012, 1045, 2318, 2000, 2131, 6015],\n",
              "  [4299, 2045, 2001, 2619, 2842, 3666, 2009, 2007, 2033, 1010],\n",
              "  [2143, 2003, 2009, 1012, 1045, 2318, 2000, 2131, 6015, 1998],\n",
              "  [2045, 2001, 2619, 2842, 3666, 2009, 2007, 2033, 1010, 1998],\n",
              "  [2003, 2009, 1012, 1045, 2318, 2000, 2131, 6015, 1998, 4299],\n",
              "  [2001, 2619, 2842, 3666, 2009, 2007, 2033, 1010, 1998, 2009],\n",
              "  [2009, 1012, 1045, 2318, 2000, 2131, 6015, 1998, 4299, 2045],\n",
              "  [2619, 2842, 3666, 2009, 2007, 2033, 1010, 1998, 2009, 4510],\n",
              "  [1012, 1045, 2318, 2000, 2131, 6015, 1998, 4299, 2045, 2001],\n",
              "  [2842, 3666, 2009, 2007, 2033, 1010, 1998, 2009, 4510, 2038],\n",
              "  [1045, 2318, 2000, 2131, 6015, 1998, 4299, 2045, 2001, 2619],\n",
              "  [3666, 2009, 2007, 2033, 1010, 1998, 2009, 4510, 2038, 1037],\n",
              "  [2318, 2000, 2131, 6015, 1998, 4299, 2045, 2001, 2619, 2842],\n",
              "  [2009, 2007, 2033, 1010, 1998, 2009, 4510, 2038, 1037, 5436],\n",
              "  [2000, 2131, 6015, 1998, 4299, 2045, 2001, 2619, 2842, 3666],\n",
              "  [2007, 2033, 1010, 1998, 2009, 4510, 2038, 1037, 5436, 999],\n",
              "  [2131, 6015, 1998, 4299, 2045, 2001, 2619, 2842, 3666, 2009],\n",
              "  [2033, 1010, 1998, 2009, 4510, 2038, 1037, 5436, 999, 1045],\n",
              "  [6015, 1998, 4299, 2045, 2001, 2619, 2842, 3666, 2009, 2007],\n",
              "  [1010, 1998, 2009, 4510, 2038, 1037, 5436, 999, 1045, 1005],\n",
              "  [1998, 4299, 2045, 2001, 2619, 2842, 3666, 2009, 2007, 2033],\n",
              "  [1998, 2009, 4510, 2038, 1037, 5436, 999, 1045, 1005, 1049],\n",
              "  [4299, 2045, 2001, 2619, 2842, 3666, 2009, 2007, 2033, 1010],\n",
              "  [2009, 4510, 2038, 1037, 5436, 999, 1045, 1005, 1049, 2183],\n",
              "  [2045, 2001, 2619, 2842, 3666, 2009, 2007, 2033, 1010, 1998],\n",
              "  [4510, 2038, 1037, 5436, 999, 1045, 1005, 1049, 2183, 2000],\n",
              "  [2001, 2619, 2842, 3666, 2009, 2007, 2033, 1010, 1998, 2009],\n",
              "  [2038, 1037, 5436, 999, 1045, 1005, 1049, 2183, 2000, 2031],\n",
              "  [2619, 2842, 3666, 2009, 2007, 2033, 1010, 1998, 2009, 4510],\n",
              "  [1037, 5436, 999, 1045, 1005, 1049, 2183, 2000, 2031, 2000],\n",
              "  [2842, 3666, 2009, 2007, 2033, 1010, 1998, 2009, 4510, 2038],\n",
              "  [5436, 999, 1045, 1005, 1049, 2183, 2000, 2031, 2000, 2156],\n",
              "  [3666, 2009, 2007, 2033, 1010, 1998, 2009, 4510, 2038, 1037],\n",
              "  [999, 1045, 1005, 1049, 2183, 2000, 2031, 2000, 2156, 2023],\n",
              "  [2009, 2007, 2033, 1010, 1998, 2009, 4510, 2038, 1037, 5436],\n",
              "  [1045, 1005, 1049, 2183, 2000, 2031, 2000, 2156, 2023, 2143],\n",
              "  [2007, 2033, 1010, 1998, 2009, 4510, 2038, 1037, 5436, 999],\n",
              "  [1005, 1049, 2183, 2000, 2031, 2000, 2156, 2023, 2143, 2153],\n",
              "  [2033, 1010, 1998, 2009, 4510, 2038, 1037, 5436, 999, 1045],\n",
              "  [1049, 2183, 2000, 2031, 2000, 2156, 2023, 2143, 2153, 3674],\n",
              "  [1010, 1998, 2009, 4510, 2038, 1037, 5436, 999, 1045, 1005],\n",
              "  [2183, 2000, 2031, 2000, 2156, 2023, 2143, 2153, 3674, 2335],\n",
              "  [1998, 2009, 4510, 2038, 1037, 5436, 999, 1045, 1005, 1049],\n",
              "  [2000, 2031, 2000, 2156, 2023, 2143, 2153, 3674, 2335, 2077],\n",
              "  [2009, 4510, 2038, 1037, 5436, 999, 1045, 1005, 1049, 2183],\n",
              "  [2031, 2000, 2156, 2023, 2143, 2153, 3674, 2335, 2077, 1045],\n",
              "  [4510, 2038, 1037, 5436, 999, 1045, 1005, 1049, 2183, 2000],\n",
              "  [2000, 2156, 2023, 2143, 2153, 3674, 2335, 2077, 1045, 2514],\n",
              "  [2038, 1037, 5436, 999, 1045, 1005, 1049, 2183, 2000, 2031],\n",
              "  [2156, 2023, 2143, 2153, 3674, 2335, 2077, 1045, 2514, 1045],\n",
              "  [1037, 5436, 999, 1045, 1005, 1049, 2183, 2000, 2031, 2000],\n",
              "  [2023, 2143, 2153, 3674, 2335, 2077, 1045, 2514, 1045, 2428],\n",
              "  [5436, 999, 1045, 1005, 1049, 2183, 2000, 2031, 2000, 2156],\n",
              "  [2143, 2153, 3674, 2335, 2077, 1045, 2514, 1045, 2428, 3305],\n",
              "  [999, 1045, 1005, 1049, 2183, 2000, 2031, 2000, 2156, 2023],\n",
              "  [2153, 3674, 2335, 2077, 1045, 2514, 1045, 2428, 3305, 2009],\n",
              "  [1045, 1005, 1049, 2183, 2000, 2031, 2000, 2156, 2023, 2143],\n",
              "  [3674, 2335, 2077, 1045, 2514, 1045, 2428, 3305, 2009, 1012],\n",
              "  [1005, 1049, 2183, 2000, 2031, 2000, 2156, 2023, 2143, 2153],\n",
              "  [2335, 2077, 1045, 2514, 1045, 2428, 3305, 2009, 1012, 2065],\n",
              "  [1049, 2183, 2000, 2031, 2000, 2156, 2023, 2143, 2153, 3674],\n",
              "  [2077, 1045, 2514, 1045, 2428, 3305, 2009, 1012, 2065, 2017],\n",
              "  [2183, 2000, 2031, 2000, 2156, 2023, 2143, 2153, 3674, 2335],\n",
              "  [1045, 2514, 1045, 2428, 3305, 2009, 1012, 2065, 2017, 1005],\n",
              "  [2000, 2031, 2000, 2156, 2023, 2143, 2153, 3674, 2335, 2077],\n",
              "  [2514, 1045, 2428, 3305, 2009, 1012, 2065, 2017, 1005, 2128],\n",
              "  [2031, 2000, 2156, 2023, 2143, 2153, 3674, 2335, 2077, 1045],\n",
              "  [1045, 2428, 3305, 2009, 1012, 2065, 2017, 1005, 2128, 1996],\n",
              "  [2000, 2156, 2023, 2143, 2153, 3674, 2335, 2077, 1045, 2514],\n",
              "  [2428, 3305, 2009, 1012, 2065, 2017, 1005, 2128, 1996, 2785],\n",
              "  [2156, 2023, 2143, 2153, 3674, 2335, 2077, 1045, 2514, 1045],\n",
              "  [3305, 2009, 1012, 2065, 2017, 1005, 2128, 1996, 2785, 1997],\n",
              "  [2023, 2143, 2153, 3674, 2335, 2077, 1045, 2514, 1045, 2428],\n",
              "  [2009, 1012, 2065, 2017, 1005, 2128, 1996, 2785, 1997, 2711],\n",
              "  [2143, 2153, 3674, 2335, 2077, 1045, 2514, 1045, 2428, 3305],\n",
              "  [1012, 2065, 2017, 1005, 2128, 1996, 2785, 1997, 2711, 2040],\n",
              "  [2153, 3674, 2335, 2077, 1045, 2514, 1045, 2428, 3305, 2009],\n",
              "  [2065, 2017, 1005, 2128, 1996, 2785, 1997, 2711, 2040, 7777],\n",
              "  [3674, 2335, 2077, 1045, 2514, 1045, 2428, 3305, 2009, 1012],\n",
              "  [2017, 1005, 2128, 1996, 2785, 1997, 2711, 2040, 7777, 1000],\n",
              "  [2335, 2077, 1045, 2514, 1045, 2428, 3305, 2009, 1012, 2065],\n",
              "  [1005, 2128, 1996, 2785, 1997, 2711, 2040, 7777, 1000, 2026],\n",
              "  [2077, 1045, 2514, 1045, 2428, 3305, 2009, 1012, 2065, 2017],\n",
              "  [2128, 1996, 2785, 1997, 2711, 2040, 7777, 1000, 2026, 4596],\n",
              "  [1045, 2514, 1045, 2428, 3305, 2009, 1012, 2065, 2017, 1005],\n",
              "  [1996, 2785, 1997, 2711, 2040, 7777, 1000, 2026, 4596, 2007],\n",
              "  [2514, 1045, 2428, 3305, 2009, 1012, 2065, 2017, 1005, 2128],\n",
              "  [2785, 1997, 2711, 2040, 7777, 1000, 2026, 4596, 2007, 7213],\n",
              "  [1045, 2428, 3305, 2009, 1012, 2065, 2017, 1005, 2128, 1996],\n",
              "  [1997, 2711, 2040, 7777, 1000, 2026, 4596, 2007, 7213, 1000],\n",
              "  [2428, 3305, 2009, 1012, 2065, 2017, 1005, 2128, 1996, 2785],\n",
              "  [2711, 2040, 7777, 1000, 2026, 4596, 2007, 7213, 1000, 1998],\n",
              "  [3305, 2009, 1012, 2065, 2017, 1005, 2128, 1996, 2785, 1997],\n",
              "  [2040, 7777, 1000, 2026, 4596, 2007, 7213, 1000, 1998, 3152],\n",
              "  [2009, 1012, 2065, 2017, 1005, 2128, 1996, 2785, 1997, 2711],\n",
              "  [7777, 1000, 2026, 4596, 2007, 7213, 1000, 1998, 3152, 2011],\n",
              "  [1012, 2065, 2017, 1005, 2128, 1996, 2785, 1997, 2711, 2040],\n",
              "  [1000, 2026, 4596, 2007, 7213, 1000, 1998, 3152, 2011, 2643],\n",
              "  [2065, 2017, 1005, 2128, 1996, 2785, 1997, 2711, 2040, 7777],\n",
              "  [2026, 4596, 2007, 7213, 1000, 1998, 3152, 2011, 2643, 4232],\n",
              "  [2017, 1005, 2128, 1996, 2785, 1997, 2711, 2040, 7777, 1000],\n",
              "  [4596, 2007, 7213, 1000, 1998, 3152, 2011, 2643, 4232, 1010],\n",
              "  [1005, 2128, 1996, 2785, 1997, 2711, 2040, 7777, 1000, 2026],\n",
              "  [2007, 7213, 1000, 1998, 3152, 2011, 2643, 4232, 1010, 2030],\n",
              "  [2128, 1996, 2785, 1997, 2711, 2040, 7777, 1000, 2026, 4596],\n",
              "  [7213, 1000, 1998, 3152, 2011, 2643, 4232, 1010, 2030, 2065],\n",
              "  [1996, 2785, 1997, 2711, 2040, 7777, 1000, 2026, 4596, 2007],\n",
              "  [1000, 1998, 3152, 2011, 2643, 4232, 1010, 2030, 2065, 2017],\n",
              "  [2785, 1997, 2711, 2040, 7777, 1000, 2026, 4596, 2007, 7213],\n",
              "  [1998, 3152, 2011, 2643, 4232, 1010, 2030, 2065, 2017, 2079],\n",
              "  [1997, 2711, 2040, 7777, 1000, 2026, 4596, 2007, 7213, 1000],\n",
              "  [3152, 2011, 2643, 4232, 1010, 2030, 2065, 2017, 2079, 1037],\n",
              "  [2711, 2040, 7777, 1000, 2026, 4596, 2007, 7213, 1000, 1998],\n",
              "  [2011, 2643, 4232, 1010, 2030, 2065, 2017, 2079, 1037, 2843],\n",
              "  [2040, 7777, 1000, 2026, 4596, 2007, 7213, 1000, 1998, 3152],\n",
              "  [2643, 4232, 1010, 2030, 2065, 2017, 2079, 1037, 2843, 1997],\n",
              "  [7777, 1000, 2026, 4596, 2007, 7213, 1000, 1998, 3152, 2011],\n",
              "  [4232, 1010, 2030, 2065, 2017, 2079, 1037, 2843, 1997, 2568],\n",
              "  [1000, 2026, 4596, 2007, 7213, 1000, 1998, 3152, 2011, 2643],\n",
              "  [1010, 2030, 2065, 2017, 2079, 1037, 2843, 1997, 2568, 1011],\n",
              "  [2026, 4596, 2007, 7213, 1000, 1998, 3152, 2011, 2643, 4232],\n",
              "  [2030, 2065, 2017, 2079, 1037, 2843, 1997, 2568, 1011, 22552],\n",
              "  [4596, 2007, 7213, 1000, 1998, 3152, 2011, 2643, 4232, 1010],\n",
              "  [2065, 2017, 2079, 1037, 2843, 1997, 2568, 1011, 22552, 5850],\n",
              "  [2007, 7213, 1000, 1998, 3152, 2011, 2643, 4232, 1010, 2030],\n",
              "  [2017, 2079, 1037, 2843, 1997, 2568, 1011, 22552, 5850, 1010],\n",
              "  [7213, 1000, 1998, 3152, 2011, 2643, 4232, 1010, 2030, 2065],\n",
              "  [2079, 1037, 2843, 1997, 2568, 1011, 22552, 5850, 1010, 2017],\n",
              "  [1000, 1998, 3152, 2011, 2643, 4232, 1010, 2030, 2065, 2017],\n",
              "  [1037, 2843, 1997, 2568, 1011, 22552, 5850, 1010, 2017, 2097],\n",
              "  [1998, 3152, 2011, 2643, 4232, 1010, 2030, 2065, 2017, 2079],\n",
              "  [2843, 1997, 2568, 1011, 22552, 5850, 1010, 2017, 2097, 2763],\n",
              "  [3152, 2011, 2643, 4232, 1010, 2030, 2065, 2017, 2079, 1037],\n",
              "  [1997, 2568, 1011, 22552, 5850, 1010, 2017, 2097, 2763, 5959],\n",
              "  [2011, 2643, 4232, 1010, 2030, 2065, 2017, 2079, 1037, 2843],\n",
              "  [2568, 1011, 22552, 5850, 1010, 2017, 2097, 2763, 5959, 2023],\n",
              "  [2643, 4232, 1010, 2030, 2065, 2017, 2079, 1037, 2843, 1997],\n",
              "  [1011, 22552, 5850, 1010, 2017, 2097, 2763, 5959, 2023, 2143],\n",
              "  [4232, 1010, 2030, 2065, 2017, 2079, 1037, 2843, 1997, 2568],\n",
              "  [22552, 5850, 1010, 2017, 2097, 2763, 5959, 2023, 2143, 1012],\n",
              "  [1010, 2030, 2065, 2017, 2079, 1037, 2843, 1997, 2568, 1011],\n",
              "  [5850, 1010, 2017, 2097, 2763, 5959, 2023, 2143, 1012, 10166],\n",
              "  [2030, 2065, 2017, 2079, 1037, 2843, 1997, 2568, 1011, 22552],\n",
              "  [1010, 2017, 2097, 2763, 5959, 2023, 2143, 1012, 10166, 1012],\n",
              "  [2065, 2017, 2079, 1037, 2843, 1997, 2568, 1011, 22552, 5850],\n",
              "  [2017, 2097, 2763, 5959, 2023, 2143, 1012, 10166, 1012],\n",
              "  [2017, 2079, 1037, 2843, 1997, 2568, 1011, 22552, 5850, 1010],\n",
              "  [2097, 2763, 5959, 2023, 2143, 1012, 10166, 1012],\n",
              "  [2079, 1037, 2843, 1997, 2568, 1011, 22552, 5850, 1010, 2017],\n",
              "  [2763, 5959, 2023, 2143, 1012, 10166, 1012],\n",
              "  [1037, 2843, 1997, 2568, 1011, 22552, 5850, 1010, 2017, 2097],\n",
              "  [5959, 2023, 2143, 1012, 10166, 1012],\n",
              "  [2843, 1997, 2568, 1011, 22552, 5850, 1010, 2017, 2097, 2763],\n",
              "  [2023, 2143, 1012, 10166, 1012],\n",
              "  [1997, 2568, 1011, 22552, 5850, 1010, 2017, 2097, 2763, 5959],\n",
              "  [2143, 1012, 10166, 1012],\n",
              "  [2568, 1011, 22552, 5850, 1010, 2017, 2097, 2763, 5959, 2023],\n",
              "  [1012, 10166, 1012],\n",
              "  [1011, 22552, 5850, 1010, 2017, 2097, 2763, 5959, 2023, 2143],\n",
              "  [10166, 1012],\n",
              "  [22552, 5850, 1010, 2017, 2097, 2763, 5959, 2023, 2143, 1012],\n",
              "  [1012],\n",
              "  [5850, 1010, 2017, 2097, 2763, 5959, 2023, 2143, 1012, 10166],\n",
              "  []])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "data_tokenized_flattened[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "HBhpxG2Ezsi1"
      },
      "outputs": [],
      "source": [
        "R, K = 10, 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGkHPrVM44C5"
      },
      "source": [
        "# Q4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "IKO9rmDYzyO_"
      },
      "outputs": [],
      "source": [
        "document_train_set = flatten_dataset_to_list(train_set[\"review_ids\"], R)\n",
        "document_valid_set = flatten_dataset_to_list(valid_set[\"review_ids\"], R)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRm7Oi0Q0hNA",
        "outputId": "70b7261e-f71a-4af8-e375-fdccc8b1d641"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4000\n",
            "1000\n"
          ]
        }
      ],
      "source": [
        "print(len(document_train_set))\n",
        "print(len(document_valid_set))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bpgCoWP48WW"
      },
      "source": [
        "# Q5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qCarhSvW0qbm"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class sentiment(Dataset):\n",
        "    def __init__(self, data):\n",
        "      self.data =data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        return self.data[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Oq1ET5oB2ry1"
      },
      "outputs": [],
      "source": [
        "train_set = sentiment(document_train_set)\n",
        "valid_set = sentiment(document_valid_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obUP4qHwHoJD"
      },
      "source": [
        "# Q6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "BS1Ibidp34uf"
      },
      "outputs": [],
      "source": [
        "#J'y arrive pas ^^'\n",
        "import random\n",
        "import itertools\n",
        "def collate_fn(batch, R, K):\n",
        "  ids, poss_con, negs_con = [], [], []\n",
        "  batch = extract_words_contexts(batch, R)\n",
        "  for word_id, pos_con in batch:\n",
        "    ids.append(word_id)\n",
        "    poss_con.append(pos_con)\n",
        "    neg_con = random.sample(data_tokenized_flattened, 2*K*R)\n",
        "    negs_con.append(neg_con)\n",
        "\n",
        "  ids = list(itertools.chain(*ids))\n",
        "  word_id = torch.tensor(ids)\n",
        "\n",
        "  poss_con = list(itertools.chain(*poss_con))\n",
        "  positive_context_ids = torch.tensor(poss_con)\n",
        "\n",
        "  negative_context_ids = list(itertools.chain(*negs_con))\n",
        "  negative_context_ids = torch.tensor(negs_con)\n",
        "\n",
        "  return {\"word_id\":ids, \"positive_context_ids\":positive_context_ids, \"negative_context_ids\": negative_context_ids}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFX4Buv1Hz4M"
      },
      "source": [
        "# Q7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "2YDT3OnNH2Oz"
      },
      "outputs": [],
      "source": [
        "batch_size = 10\n",
        "dataloader = DataLoader(\n",
        "        dataset=data_tokenized_flattened, batch_size=batch_size, collate_fn=lambda x: collate_fn(x, R, K)\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q8"
      ],
      "metadata": {
        "id": "q-Iu33Ur503h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "9C31Spk1H8HT",
        "outputId": "df99c4f9-6cf1-4824-e8b8-e6ae951dcecd"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-374ddc0c5dae>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"R = {R}, K = {K}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m#print(f\"Word IDs shape: {batch['word_id'].shape}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#print(f\"Positive Context IDs shape: {batch['positive_context_ids'].shape}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#print(f\"Negative Context IDs shape: {batch['negative_context_ids'].shape}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-65717ed77beb>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m dataloader = DataLoader(\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_tokenized_flattened\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     )\n",
            "\u001b[0;32m<ipython-input-17-0529b631d677>\u001b[0m in \u001b[0;36mcollate_fn\u001b[0;34m(batch, R, K)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposs_con\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegs_con\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_words_contexts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mword_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_con\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mposs_con\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_con\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ],
      "source": [
        "for i, batch in enumerate(dataloader):\n",
        "    print(f\"R = {R}, K = {K}\")\n",
        "    #print(f\"Word IDs shape: {batch['word_id'].shape}\")\n",
        "    #print(f\"Positive Context IDs shape: {batch['positive_context_ids'].shape}\")\n",
        "    #print(f\"Negative Context IDs shape: {batch['negative_context_ids'].shape}\")\n",
        "    print(\"Word IDs:\", batch['word_id'])\n",
        "    print(\"Positive Context:\", batch['positive_context_ids'])\n",
        "    print(\"Negative Context:\", batch['negative_context_ids'])\n",
        "    if i == 2:\n",
        "      break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q9\n",
        "\n"
      ],
      "metadata": {
        "id": "a1euf5ZN6Ai-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0CnWBfWH6EnP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f33ddff77b7e492a8f87472efe1c4959": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e43b714ab839464a9c78388ef17852b9",
              "IPY_MODEL_e22e9ef8c1ae4505af65c2959ad955b0",
              "IPY_MODEL_f885886b57364ae289e9959d1b74de07"
            ],
            "layout": "IPY_MODEL_f7e0bcc4071b416583042c438444de85"
          }
        },
        "e43b714ab839464a9c78388ef17852b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6593b9e1678444e5b0947bf8f2e49244",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ff1248dd9bee4a7e83a5b02c271af9b0",
            "value": "Map:â€‡100%"
          }
        },
        "e22e9ef8c1ae4505af65c2959ad955b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_444c687d59da438e947fd0f92a8de494",
            "max": 5000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c1af1e1884f4cd0aac50ff8303d9761",
            "value": 5000
          }
        },
        "f885886b57364ae289e9959d1b74de07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_beee8008bf324697830443b8113a8676",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0562e74db7aa4bff9018464bd022028c",
            "value": "â€‡5000/5000â€‡[00:35&lt;00:00,â€‡145.23â€‡examples/s]"
          }
        },
        "f7e0bcc4071b416583042c438444de85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6593b9e1678444e5b0947bf8f2e49244": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff1248dd9bee4a7e83a5b02c271af9b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "444c687d59da438e947fd0f92a8de494": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c1af1e1884f4cd0aac50ff8303d9761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "beee8008bf324697830443b8113a8676": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0562e74db7aa4bff9018464bd022028c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}